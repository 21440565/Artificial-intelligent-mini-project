{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project of COMP7015\n",
    "\n",
    "Welcome to the Project of COMP7015! \n",
    "\n",
    "This project consists of two parts, i.e., Part 1: Simple Classification with Neural Network & Part 2: Adversarial Examples for Neural Networks. Through trying this project, you are expected to have a brief understanding on the image classification and the special vulnerability of Neural Networks induced by adversarial examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Simple Classification with Neural Network\n",
    "\n",
    "In this part, you will implement a simple neural network to classify grayscale images of handwritten digits (0 - 9) from the MNIST dataset (in the attachment, i.e., ```images_train.npy/images_test.npy/labels_train.npy/labels_test.npy```). The dataset contains 60,000 training images and 10,000 testing images of handwritten digits. Each image is 28×28 pixels in size, and is generally represented as a flat vector of 784 numbers. It also includes labels for each example, a number indicating the actual digit (0 - 9) handwritten in that image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) **[5 points]** Please realize an util function: <em>one_hot_labels</em>.\n",
    "\n",
    "In the implementation of the cross entropy loss, it is much convenient if numerical labels are transformed into one-hot labels. For example, numerical label 5 -> one-hot label [0,0,0,0,0,1,0,0,0,0]. Accordingly, the cross entropy loss can be written as follow:\n",
    "\n",
    "$CE(y,\\hat y)=-\\sum_{k=1}^K y_k \\log \\hat y_k$,\n",
    "\n",
    "where $\\hat y$ is the softmax outputs from the model for the training example, $y$ is the one-hot (ground-truth) label, and the subscript refers to the element of $y$ at the coordinate $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_labels(labels):\n",
    "    one_hot_labels = np.zeros((labels.size, 10))\n",
    "    ### YOUR CODE HERE\n",
    "    for i in range(labels.size):\n",
    "        one_hot_labels[i, labels[i]] = 1\n",
    "    ### END YOUR CODE\n",
    "    return one_hot_labels\n",
    "\n",
    "# test\n",
    "test = np.array([7])\n",
    "print(one_hot_labels(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, MNIST dataset is loaded from the following files:\n",
    "\n",
    "    images_train.npy: 60k images with normalized features, the dimension of image features is 784.\n",
    "    images_test.npy\n",
    "    labels_train.npy: corresponding numerical labels (0-9).\n",
    "    labels_test.npy\n",
    "    \n",
    "Note that, the original training images and labels are separated into a set of 50k data for training and 10k data for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(images_file, labels_file):\n",
    "    x = np.load(images_file)\n",
    "    y = np.load(labels_file)\n",
    "    return x, y\n",
    "\n",
    "def prepare_data():\n",
    "    \n",
    "    trainData, trainLabels = readData('images_train.npy', 'labels_train.npy')\n",
    "    trainLabels = one_hot_labels(trainLabels)\n",
    "    p = np.random.permutation(60000)\n",
    "    trainData = trainData[p,:]\n",
    "    trainLabels = trainLabels[p,:]\n",
    "\n",
    "    valData = trainData[0:10000,:]\n",
    "    valLabels = trainLabels[0:10000,:]\n",
    "    trainData = trainData[10000:,:]\n",
    "    trainLabels = trainLabels[10000:,:]\n",
    "\n",
    "\n",
    "    testData, testLabels = readData('images_test.npy', 'labels_test.npy')\n",
    "    testLabels = one_hot_labels(testLabels)\n",
    "\n",
    "    return trainData, trainLabels, valData, valLabels, testData, testLabels\n",
    "\n",
    "# load data for train, validation, and test. \n",
    "trainData, trainLabels, devData, devLabels, testData, testLabels = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) **[5 points]** Please realize the softmax function as well as the sigmoid function: <em>softmax(x)</em> and <em>sigmoid(x)</em>.\n",
    "\n",
    "The $k$-th element of softmax is calculated via:\n",
    "\n",
    "$softmax(x)_k=\\frac {e^{x_k}}{\\sum_j e^{x_j}}=\\frac {e^{x_k+c}}{\\sum_j e^{x_j+c}}$\n",
    "\n",
    "The last equation holds since adding a constant won't change softmax results. Note that, you may encounter an overflow when softmax computes the exponential, so please using the 'max' tricks to avoid this problem.  \n",
    "\n",
    "The sigmoid is calculated by:\n",
    "\n",
    "$sigmoid(x)=\\frac {1}{1+e^{-x}} = \\frac {e^x}{e^x + 1}$\n",
    "\n",
    "For numerical stability, please use the 1st equation for positive inputs, and the 2nd equation for negative inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    x is of shape: batch_size * #class\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    len_x_shape = len(x.shape)\n",
    "    if (len_x_shape) > 1:\n",
    "        x_exp = np.exp(x)\n",
    "        x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "        s = x_exp / x_sum\n",
    "    else:\n",
    "        x_exp = np.exp(x)\n",
    "        x_sum = np.sum(x_exp, keepdims=True)\n",
    "        s = x_exp / x_sum\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return s\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    x is of shape: batch_size * dim_hidden\n",
    "    \"\"\"\n",
    "    ## YOUR CODE HERE\n",
    "\n",
    "    #1st equation for positive inputs\n",
    "    if x.all()>= 0:\n",
    "        s = 1 / (1 + np.exp(-x))\n",
    "    #2nd equation for negative inputs\n",
    "    else:\n",
    "        s = np.exp(x) / (np.exp(x) + 1) \n",
    "\n",
    "    ### END YOUR CODE\n",
    "\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) **[10 points]** Please complete the forward propagation: <em> forward_prop(data, labels, params)</em>, based on the following descriptions\n",
    "\n",
    "It is time to realize the forward propagation for a 2-layer neural network. Here, sigmoid is used as the activation function, and the softmax is used as the link function. Formally,\n",
    "\n",
    "hidden layer: $h=sigmoid(z_1)=sigmoid(x W_1+b_1)$\n",
    "\n",
    "output layer: $\\hat y = softmax(z_2) = softmax(h W_2 + b_2)$\n",
    "\n",
    "loss: $L = CE(y,\\hat y)$\n",
    "\n",
    "Therein, $z_1, z_2$ are the outputs (before activation function) from the hidden layer and output layer; $W_1, b_1, W_2$, and $b_2$ are the learnable parameters. Concretely, $W_1$ and $b_1$ denote the weight matrix and the bias vector for the hidden layer of the network. Similarly, $W_2$ and $b_2$ are the weights and biases for the output layer.  Note that, in computing the loss value, we should use np.log(y+1e-16) instead of np.log(y) to avoid NaN (Not a Number) error in the case log(0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(data, labels, params):\n",
    "    \"\"\"\n",
    "    return hidder layer, output(softmax) layer and loss\n",
    "        data is of shape: batch_size * dim_x\n",
    "        labels is of shape: batch_size * #class\n",
    "    \"\"\"\n",
    "    W1 = params['W1'] # dim_x * dim_hidden\n",
    "    b1 = params['b1'] # batch_size * dim_hidden\n",
    "    W2 = params['W2'] # dim_hidden * #class\n",
    "    b2 = params['b2'] # batch_size x #class\n",
    "    \n",
    "    z1 = data.dot(W1) + b1\n",
    "    h = sigmoid(z1)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    z2 = h.dot(W2) + b2\n",
    "    y = softmax(z2)\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    loss = - np.multiply(labels, np.log(y + 1e-16)).sum()\n",
    "    loss /= data.shape[0]\n",
    "    \n",
    "    return h, y, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) **[10 points]** Please realize the corresponding backward propagation: <em>backward_prop(data, labels, params)</em>.\n",
    "\n",
    "Based on the forward_prop, you can implement the corresponding function for backward propagation. Here are some useful derivation about the link rule that can facilitate your implementation:\n",
    "\n",
    "$\\delta_1 = \\nabla_{z_2} L = \\hat y - y$， where $\\nabla$ refer to the Partial derivative.\n",
    "\n",
    "$\\nabla_{W_2} L = \\delta_1 \\nabla_{W_2} z_2 = h^T \\delta_1$, where $T$ is the transpose operator. \n",
    "\n",
    "$\\nabla_{b_2} L = \\delta_1 \\nabla_{b_2} z_2 = \\delta_1$\n",
    "\n",
    "$\\nabla_{h} L = \\delta_1 \\nabla_{h} z_2 = \\delta_1 W_2^T$\n",
    "\n",
    "$\\delta_2 = \\nabla_{z_1} L = (\\delta_1 W_2^T) \t\\circ h(1-h) $, where $\\circ$ is the element-wise product\n",
    "\n",
    "$\\nabla_{W_1} L = \\delta_2 \\nabla_{W_1} z_1 = x^T \\delta_2$\n",
    "\n",
    "$\\nabla_{b_1} L = \\delta_2 \\nabla_{b_1} z_1 = \\delta_2$\n",
    "\n",
    "Note that, the regularization hyper-parameter lamb for weight decay is ignored in above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(data, labels, params):\n",
    "    \"\"\"\n",
    "    return gradient of parameters\n",
    "    \"\"\"\n",
    "    W1 = params['W1']\n",
    "    b1 = params['b1']\n",
    "    W2 = params['W2']\n",
    "    b2 = params['b2']\n",
    "    \n",
    "    h, y, cost = forward_prop(data, labels, params)\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    delta_1 = y - labels\n",
    "    gradW2 = np.dot(h.T,delta_1)\n",
    "    gradb2 = np.sum(delta_1, axis=0, keepdims=True)\n",
    "    \n",
    "    ### END YOUR CODE\n",
    "    delta_2 = np.multiply(np.dot(delta_1, W2.T), h * (1 - h))\n",
    "    gradW1 = np.dot(data.T, delta_2)\n",
    "    gradb1 = np.sum(delta_2, axis=0, keepdims=True)\n",
    "    \n",
    "    lamb = params['lambda']\n",
    "    if lamb > 0:\n",
    "        gradW2 += lamb * W2\n",
    "        gradW1 += lamb * W1\n",
    "    \n",
    "    # The gradients are normalized by batch_size here.\n",
    "    grad = {}\n",
    "    B = data.shape[0]\n",
    "    grad['W1'] = gradW1 / B\n",
    "    grad['W2'] = gradW2 / B\n",
    "    grad['b1'] = gradb1 / B\n",
    "    grad['b2'] = gradb2 / B\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y, labels):\n",
    "    \"\"\"\n",
    "    return accuracy of y given (true) labels. \n",
    "    \"\"\"\n",
    "    pred = np.zeros_like(y)\n",
    "    pred[np.arange(y.shape[0]), np.argmax(y, axis=1)] = 1\n",
    "    res = np.abs((pred - labels)).sum(axis=1)\n",
    "    acc = res[res == 0].shape[0] / res.shape[0]\n",
    "    return acc\n",
    "def update_params(params, grad, learning_rate):\n",
    "    params['W1'] -= learning_rate * grad['W1']\n",
    "    params['W2'] -= learning_rate * grad['W2']\n",
    "    params['b1'] -= learning_rate * grad['b1']\n",
    "    params['b2'] -= learning_rate * grad['b2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) **[5 points]** Please complete the training procedure: <em>nn_train(trainData, trainLabels, devData, devLabels, **argv)</em>.\n",
    "\n",
    "As a convention, parameters $W_1, W_2$ should be randomly initialized with standard gaussian variables, and parameters $b_1, b_2$ should initialized by 0. You can run nn_train with different values of the hyper-parameter reg_strength to validate the impact of the regularization to the network performance (e.g. reg_strength=0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-84f028fc8fec>:29: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,"
     ]
    }
   ],
   "source": [
    "def nn_train(trainData, trainLabels, devData, devLabels, \n",
    "             num_hidden=300, learning_rate=5, batch_size=1000, num_epochs=30,\n",
    "             reg_strength=0):\n",
    "    (m, n) = trainData.shape\n",
    "    params = {}\n",
    "\n",
    "    N = m\n",
    "    D = n\n",
    "    K = trainLabels.shape[1]\n",
    "    H = num_hidden\n",
    "    B = batch_size\n",
    "    params['W1'] = np.random.standard_normal((n, H))\n",
    "    params['b1'] = np.zeros((1, H), dtype=float)\n",
    "    params['W2'] = np.random.standard_normal((num_hidden, K))\n",
    "    params['b2'] = np.zeros((1, K), dtype=float)\n",
    "    params['lambda'] = reg_strength\n",
    "    num_iter = int(N / B)\n",
    "    tr_loss, tr_metric, dev_loss, dev_metric = [], [], [], []\n",
    "    for i in range(num_epochs):\n",
    "        print(i, end=',')\n",
    "        for j in range(num_iter):\n",
    "            batch_data = trainData[j * B: (j + 1) * B]\n",
    "            batch_labels = trainLabels[j * B: (j + 1) * B]\n",
    "            ### YOUR CODE HERE\n",
    "\n",
    "            grad = backward_prop(batch_data,batch_labels,params)\n",
    "            update_params(params,grad,learning_rate)\n",
    "            \n",
    "            ### END YOUR CODE\n",
    "        \n",
    "        _, _y, _cost = forward_prop(trainData, trainLabels, params)\n",
    "        tr_loss.append(_cost)\n",
    "        tr_metric.append(calc_accuracy(_y, trainLabels))\n",
    "        _, _y, _cost = forward_prop(devData, devLabels, params)\n",
    "        dev_loss.append(_cost)\n",
    "        dev_metric.append(calc_accuracy(_y, devLabels))\n",
    "    \n",
    "    return params, tr_loss, tr_metric, dev_loss, dev_metric\n",
    "\n",
    "num_epochs = 30\n",
    "params, tr_loss, tr_metric, dev_loss, dev_metric = nn_train(\n",
    "    trainData, trainLabels, devData, devLabels, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) **[10 points]** Please provide the accuracy curves and results by running the following codes.\n",
    "\n",
    "After training, we can plot the training and validation loss/accuracy curves to assess the model and the learning procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAEHCAYAAABss8qVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABe4ElEQVR4nO3dd5hU5dn48e+9s7132EJZOkgHEQUExAY2xGCJLaYYY4mvvslPYhJLzPuGGE000YTXGA1JVIyxgRILKmCNtKW3pe6yC2zvfZ7fH+fsMizbWHZ2Znbuz3Wd67TnnLlnHA/3PvMUMcaglFJKKaWUOn0Bng5AKaWUUkopX6XJtFJKKaWUUl2kybRSSimllFJdpMm0UkoppZRSXaTJtFJKKaWUUl2kybRSSimllFJdFOjpAE5XYmKiGThwoKfDUEqpLtmwYUOBMSbJ3a8jIi8AlwPHjTGjWzkvwNPAPKAK+JYxZqN97lL7nAN43hiz2D4eD7wKDAQOAtcaY4rbi0Of2UopX9aZZ7bPJdMDBw5k/fr1ng5DKaW6REQO9dBL/RV4BvhbG+fnAkPt5RzgT8A5IuIAngUuAnKAdSKy3BizA1gEfGSMWSwii+z9B9oLQp/ZSilf1plntjbzUEqpXsgYsxYoaqfIVcDfjOUrIFZEUoApQJYxZr8xpg5YZpdtumapvb0UmO+W4JVSyodoMq2UUv4pDch22c+xj7V1HKCPMSYPwF4n90CcSinl1TSZVkop/yStHDPtHO/8jUVuF5H1IrI+Pz+/S8EppZSv8Lk200op96uvrycnJ4eamhpPh+KzQkNDSU9PJygoyNOhtCUH6Oeynw7kAsFtHAc4JiIpxpg8u0nI8dZubIx5DngOYPLkyack4vr96jof+F4p5Xc0mVZKnSInJ4eoqCgGDhyINeiDOh3GGAoLC8nJySEjI8PT4bRlOXC3iCzD6oBYaifJ+cBQEckAjgDXA990ueZWYLG9frsrL6zfr67xke+VUn5Hk2ml1Clqamo00TkDIkJCQgKebOIgIq8As4BEEckBHgaCAIwxS4CVWMPiZWENjXebfa5BRO4G3scaGu8FY8x2+7aLgX+KyHeAw8DCrsSm36+u8YbvlVLqVJpMK6VapYnOmfH052eMuaGD8wa4q41zK7GS7ZbHC4E53RGfpz8fX6Wfm1Lexz+S6S3/hLpKmHybpyNRSimllFLdpNFpqKxroKKmgcraBsprre2KWnuxt9Niw7hmUrpbYvCPZHrH23B8pybTSvmIkpISXn75Ze68887TvnbevHm8/PLLxMbGdqr8I488QmRkJD/60Y9O+7WUb+rJ75dS6vRU1DZwvKyG4+W1FFXWUVxVR3FlHcVV9a1ul9U0dOq+s4YnaTJ9RlInwK53oLoEwmI9HY1SqgMlJSX88Y9/bDXZaWxsxOFwtHntypWntE5Q6iT6/VKqZ9U3OimqrKOgopbCijryy2s5Xl7L8XIrac4vO7FdVdfY6j0igh3EhgcTFxFEXHgw/ePDiQsPIiY8mOjQQCJDAokMDSQiJJCoEGsdGRJIlH0syOG+0aD9J5kGyNsMg2Z6NhalVIcWLVrEvn37GD9+PBdddBGXXXYZjz76KCkpKWRmZrJjxw7mz59PdnY2NTU13Hvvvdx+++3AiemrKyoqmDt3LtOnT+eLL74gLS2Nt99+m7CwsDZfNzMzkzvuuIOqqioGDx7MCy+8QFxcHL///e9ZsmQJgYGBjBo1imXLlrFmzRruvfdewGrHunbtWqKionrk81Fnpie/XytWrOCXv/wldXV1JCQk8NJLL9GnTx8qKiq45557WL9+PSLCww8/zDXXXMN7773Hgw8+SGNjI4mJiXz00Uee+IiU6lBVXQMF5XXkV9SSX15LQUVtc7LcvK601qXV9a3eIyLYQXJ0KMlRIYxJjyU5KsRaokNIjgolITKYuPBgYsODCAls+49cT/OvZDp3oybTSp2mR1dsZ0duWbfec1RqNA9fcVab5xcvXsy2bdvIzMwEYPXq1Xz99dds27ateUiwF154gfj4eKqrqzn77LO55pprSEhIOOk+e/fu5ZVXXuHPf/4z1157La+//jo33XRTm697yy238Ic//IGZM2fy0EMP8eijj/LUU0+xePFiDhw4QEhICCUlJQA88cQTPPvss0ybNo2KigpCQ0PP7EPxU739+zV9+nS++uorRITnn3+exx9/nCeffJLHHnuMmJgYtm7dCkBxcTH5+fl873vfY+3atWRkZFBU1N5s8Ep1r5r6Rooq65qX4qo6CivsdWUdRXaSnF9RS0F5LZVt1CDHhgeRGBlCQkQwI/tGkxAZbO1HBpMQEUJiZDAJkVbSHBHSO9LQ3vEuOhIeD3EDIXeTpyNRSnXRlClTThpb9/e//z1vvvkmANnZ2ezdu/eUZCcjI4Px48cDMGnSJA4ePNjm/UtLSykpKWHmTOsP7ltvvZWFC62R38aOHcuNN97I/PnzmT9/PgDTpk3j/vvv58Ybb2TBggWkp7unLZ7qGe76fuXk5HDdddeRl5dHXV1d82usWrWKZcuWNZeLi4tjxYoVnH/++c1l4uPju/MtKj9W1+Akr7SaI8XV5JTY6+JqjpRUkVtSQ0FF280rAgTiwoOJj7CS4nHpsSRGhpAYFUxSZAiJUSHW2k6Y3dmcwlv5RzINVu10zgZPR6GUz2mvhq8nRURENG+vXr2aVatW8eWXXxIeHs6sWbNanU0vJCSkedvhcFBdXd2l13733XdZu3Yty5cv57HHHmP79u0sWrSIyy67jJUrVzJ16lRWrVrFiBEjunR/f9bbv1/33HMP999/P1deeSWrV6/mkUceAawJWFoOc9faMaU64nQaCipqySutIa+0mrzSGo6W1pBbWkOunTgfK6/BuMxFKgLJUSGkx4Uzvl8sSVEhxEdYCXNceDAJkdZ2fHgwMWFBBATo97I9fpRMT4Ttb0JlAUQkejoapVQ7oqKiKC8vb/N8aWkpcXFxhIeHs2vXLr766qszfs2YmBji4uL49NNPmTFjBn//+9+ZOXMmTqeT7OxsZs+ezfTp03n55ZepqKigsLCQMWPGMGbMGL788kt27dqlybSP6MnvV2lpKWlpaQAsXbq0+fjFF1/MM888w1NPPQVYzTzOPfdc7rrrLg4cONDczENrp/1be4ny0dJqcktqOFZWQ4PTnHRdcGAAKTGh9I0OZdqQRNLiwkiPDSM9Loy0uDBSYsIIDvS/GmR38aNkuqnd9CYYepFnY1FKtSshIYFp06YxevRo5s6dy2WXXXbS+UsvvZQlS5YwduxYhg8fztSpU7vldZcuXdrcAXHQoEG8+OKLNDY2ctNNN1FaWooxhvvuu4/Y2Fh+/vOf88knn+BwOBg1ahRz587tlhiU+/Xk9+uRRx5h4cKFpKWlMXXqVA4cOADAz372M+666y5Gjx6Nw+Hg4YcfZsGCBTz33HMsWLAAp9NJcnIyH3744Rm9V+XdjDHkl9dyoKCSQ4VVHCysJLu4ulOJckpMKFMy4ukbE0pqTCh9Y8Kaj8dHBOuvHD1IjDEdl/IikydPNuvXrz/9C2vKYHF/mP0gzPx/3R+YUr3Izp07GTlypKfD8HmtfY4issEYM9lDIfW41p7Z+v06M/r5+RZjDPkVtezPr+RQYSUHCqo4VFjJwUJr7dpWOTBA7JrjUFJckmNNlD2nM89s/6mZDo2GxKHaCVEppZRS3a6qroEDBZXsz7eWAwUV7C+o5EB+JeW1JyYWCXII/eLDGZgQwbmDEhiYGM6AhAgyEiJIjQ0l0A878Pk6/0mmwWrqsX+Np6NQSimllA8qr6nnUGEVh4uq7HUlBwus5hl5pSd3Uk2LDWNQUgQLJqaRkRhBRlIkgxIjSInRhLm38bNkeiJseRXK8iA6xdPRKKWUUsrLGGM4VlbLlpwSduSVcbCgkkNFVRwurKKwsu6ksgkRwfRPCOfcQQkMSoogIzGSQUkRDEyIICzYeycZUd3Lz5Jpl8lboi9rv6xSSimler3j5TVszSllS04p246UsuVIKfnltYA1hFxqTBj948O5+Kw+9I+PYEBCOP3jwxmQEE5UaJCHo1fewL+S6b5jQBxWu+kRmkwrpZRS/qS8pp4tOaVsOlzM5pxStuaUcrTMap4RIDAkOZIZQxMZmxbDmPRYRqVEaw2z6pB/JdPB4ZA8UjshKqWUUr1co9Ow93g5mw6XkHm4hE3Zxew9XtE8ecmgpAjOHZzA6LQYxqbHMColutdMb616lv99a1InwK53wRjr9xullNd75JFHiIyM5Ec/+pFX3Ef1Lvq96B3yy2vJzC5h0+FiMrNL2JxdQqU97FxceBAT+sdx+dhUJvSPZWx6LDFh2kRDdQ//TKY3/R1KDkPcAE9Ho5RSSqnTVNvQyI7cMjYdLmGTnUDnFFvTuQcGCKNSo7lmUjoT+scyoV8cAxLCdWxm5Tb+NzaLaydEpZTX+p//+R+GDx/OhRdeyO7du5uP79u3j0svvZRJkyYxY8YMdu3aRWlpKQMHDsTpdAJQVVVFv379qK+vb/P+mZmZTJ06lbFjx3L11VdTXFwMwO9//3tGjRrF2LFjuf766wFYs2YN48ePZ/z48UyYMKHdqai9hYhcKiK7RSRLRBa1cj5ORN4UkS0i8rWIjLaPDxeRTJelTET+yz73iIgccTk3r4ffVrdxx/drxYoVnHPOOUyYMIELL7yQY8eOAVBRUcFtt93GmDFjGDt2LK+//joA7733HhMnTmTcuHHMmTOnh965byqtqufdLXk8umI785/9nDEPf8DVf/yCX7yzgw0HixibHsNP543kX3ecy7ZHL2H53dP5xVWjuXpCOgMTIzSRVm7lfzXTfc4CR7DVbvqsqz0djVLe79+L4OjW7r1n3zEwd3Gbpzds2MCyZcvYtGkTDQ0NTJw4kUmTJgFw++23s2TJEoYOHcp//vMf7rzzTj7++GPGjRvHmjVrmD17NitWrOCSSy4hKKjtn3FvueUW/vCHPzBz5kweeughHn30UZ566ikWL17MgQMHCAkJoaSkBIAnnniCZ599lmnTplFRUUFoaGi3fhzdTUQcwLPARUAOsE5ElhtjdrgUexDINMZcLSIj7PJzjDG7gfEu9zkCvOly3e+MMU90W7C96Ps1ffp0vvrqK0SE559/nscff5wnn3ySxx57jJiYGLZutd5ncXEx+fn5fO9732Pt2rVkZGRQVFTUvZ+Bj3M6Ddtzy1i9+zir9+Sz6XAxTgOhQQGMTYvltmkDmdA/lvH94ugb493/P6rez/+S6cAQK6E+ojXTSnmrTz/9lKuvvprw8HAArrzySsCq4fviiy9YuHBhc9naWmsIq+uuu45XX32V2bNns2zZMu688842719aWkpJSQkzZ84E4NZbb22+59ixY7nxxhuZP38+8+fPB2DatGncf//93HjjjSxYsID09PRuf8/dbAqQZYzZDyAiy4CrANdkehTwKwBjzC4RGSgifYwxx1zKzAH2GWMO9VDcPcJd36+cnByuu+468vLyqKurIyMjA4BVq1axbNmy5nJxcXGsWLGC888/v7lMfHy8e96sDymurGPt3nzW7Mln7Z58CiqsMZ3HpMVw1+whzByWxLh+sQTphCfKy/hfMg3W5C1bXwOnEwL0f0ql2tVODZ87tfazrNPpJDY2lszMzFPOXXnllfzkJz+hqKiIDRs2cMEFF3Tpdd99913Wrl3L8uXLeeyxx9i+fTuLFi3isssuY+XKlUydOpVVq1YxYsSILt2/h6QB2S77OcA5LcpsBhYAn4nIFGAAkA64JtPXA6+0uO5uEbkFWA/8tzGmuOWLi8jtwO0A/fv3bz/SXvT9uueee7j//vu58sorWb16NY888ghgTQLS8vVaO+ZvGp2GLTklrNljJdCbs0twGogND+L8oUnMHJbE+cOSSIoK8XSoSrXLPzPJ1AlQWwZF+z0diVKqFeeffz5vvvkm1dXVlJeXs2LFCgCio6PJyMjgtddeA6yEZPPmzQBERkYyZcoU7r33Xi6//HIcjrbHho2JiSEuLo5PP/0UgL///e/MnDkTp9NJdnY2s2fP5vHHH6ekpISKigr27dvHmDFjeOCBB5g8eTK7du1y8ydwxlrL0kyL/cVAnIhkAvcAm4CG5huIBANXAq+5XPMnYDBWM5A84MnWXtwY85wxZrIxZnJSUlIX34L7uOv7VVpaSlpaGgBLly5tPn7xxRfzzDPPNO8XFxdz7rnnsmbNGg4cOADgN808jpfV8Nr6bO5+eSOTfvkhV//xC57+aC9Op+HuC4byxp3nseFnF/H7GyZwzaR0TaSVT3BbzbSIvABcDhw3xoxu5bwATwPzgCrgW8aYnml74doJMXFIj7ykUqrzJk6cyHXXXcf48eMZMGAAM2bMaD730ksv8YMf/IBf/vKX1NfXc/311zNu3DjA+il+4cKFrF69usPXWLp0KXfccQdVVVUMGjSIF198kcbGRm666SZKS0sxxnDfffcRGxvLz3/+cz755BMcDgejRo1i7ty57nrr3SUH6Oeynw7kuhYwxpQBt0Hz8/iAvTSZC2x0bfbhui0ifwbe6fbIe4C7vl+PPPIICxcuJC0tjalTpzYnyj/72c+46667GD16NA6Hg4cffpgFCxbw3HPPsWDBApxOJ8nJyXz44Yduf+89ra7ByfpDRXbTjQJ25pUBkBgZwpwRfTh/WCIzhiYRHxHs4UiV6joxpmVlRTfdWOR8oAL4WxvJ9Dys2pB5WD8/Pm2Mafkz5CkmT55s1q9ff2bBNTbAr9Jh8m1w6a/O7F5K9UI7d+5k5MiRng7D57X2OYrIBmPMZHe+rogEAnuw2jwfAdYB3zTGbHcpEwtUGWPqROR7wAxjzC0u55cB7xtjXnQ5lmKMybO37wPOMcZc314srT2z9ft1Zrz986upb2TNnnxWbs3jo53HqahtIDBAmDwwjvOHWc03RvaNJiDAv5u5KN/QmWe222qmjTFrRWRgO0Wuwkq0DfCViMS6PqjdyhEIKWO1E6JSqlcyxjSIyN3A+4ADeMEYs11E7rDPLwFGAn8TkUasjonfabpeRMKxRgL5fotbPy4i47GajBxs5bzyU1V1DazebSXQH+86TlVdI7HhQcwb05cLR/bhvCGJROrsgqqX8uQ3u7UOMmlY7fBOclqdWTordSJsXGrVUjv0f3ClVO9ijFkJrGxxbInL9pfA0DaurQISWjl+czeHqXxYZW0DH+86zr+35fHJrnyq6xtJiAjmqvFpzBvTl6mDEnTkDeUXPJlFdqaDjHXQmOeA58D6ybBbXj11AvznT1Cw2xoqTyl1Eh1t4My4qwldb6Hfr67x9PeqsKKWj3Yd54Ptx/h0bz61DU4SI0P4xqR05o7py5SB8QRqAq38jCeT6Q47yLhV2kRrnbtJk2mlWggNDaWwsJCEhARNeLrAGENhYaHXT+7iKfr96hpPfa8OFVby4Y5jfLD9GOsPFeE0kBoTyg1T+jNvTAqTBsTh0PbPyo95MplejjVe6TKsDoilPdJeukn8YAiOspLpCTf12Msq5QvS09PJyckhPz/f06H4rNDQUF+Y3MUj9PvVdT3xvTLGsPVIaXMCvftYOQAjU6K5+4KhXDyqD2elRusfQkrZ3Dk03ivALCBRRHKAh4EgaG63txJrJI8srKHxbnNXLK0KCIDU8doJUalWBAUFNc/MplR30++Xd8ovr+XVdYd55etsjpRUEyAwJSOehy4fxUWj+tAvPtzTISrlldw5mscNHZw3wF3uev1OSZ0A/1kCDXUQqGNcKqWU8i/GGDYeLuHvXx7k3a151Dcapg9J5P6LhnHBiGTidPxnpTrk38NYpE6Axjo4vv3ERC5KKaVUL1dT38jyzFyWfnmQ7bllRIUEcuM5A7j53AEMTor0dHhK+RT/TqZdOyFqMq2UUqqXO1xYxT/+c4hX12VTWl3PsD6R/HL+aK6ekEaEjgOtVJf49/85sQMgLM5qNz35256ORimllHKL3UfLeWrVHt7bfpQAES45qw+3nDuQczLitSOhUmfIv5NpEatGOjfT05EopZRS3W5ffgVPrdrLO1tyiQgO5M5Zg7lp6gBSYsI8HZpSvYZ/J9NgzYT42e+gvhqC9OGilFLK9x0qrOTpj/by1qYjhAQ6uGPmYG6fMUg7FCrlBppMp04A0whHt0K/KZ6ORimllOqynOIq/vBRFv/amENggPCd6Rl8f+ZgEiNDPB2aUr2WJtOunRA1mVZKKeWDjpbW8Mwne3l1XTaCcPPUAdw5azDJ0ToLp1Lupsl0VApE9tHJW5RSSvmchkYnz392gN99uAenMVw7uR93XzBE20Qr1YM0mRax2k3nbvJ0JEoppVSnbc8t5YHXt7DtSBmXnNWHn102SmcpVMoDNJkGq930nvegthxCojwdjVJKKdWmmvpGfv/RXv5v7X7iwoP5040TmTsmxdNhKeW3/CKZ/vpAEZW1Dcwekdx6gdQJgIG8zTBweo/GppRSSnXW1weKWPT6FvYXVLJwUjo/vWwkseE6QodSnuQXyfQfV2dxrKy2g2Qaq6mHJtNKKaW8THlNPY+/t5u/f3WI9Lgw/v6dKcwYmuTpsJRS+EkyPTgpki/3FeJ0GgICWpnpKTIJYvppJ0SlVK8hIpcCTwMO4HljzOIW5+OAF4DBQA3wbWPMNvvcQaAcaAQajDGT7ePxwKvAQOAgcK0xprgH3o5f+3jXMX765jaOltXw7WkZ/OiSYYQH+8U/30r5hABPB9AThiRHUtvg5EhJdduFUidoJ0SlVK8gIg7gWWAuMAq4QURGtSj2IJBpjBkL3IKVeLuabYwZ35RI2xYBHxljhgIf2fvKTXKKq7jr5Y18+6/riQoN5PUfnMdDV4zSRFopL+MXyfTgpEgAsvIr2i6UOgGKD0BVUQ9FpZRSbjMFyDLG7DfG1AHLgKtalBmFlRBjjNkFDBSRPh3c9ypgqb29FJjfbRGrZpW1DTz5wW7mPLmGj3Ye474Lh/HOPTOY2D/O06EppVrhF8n0kGQrmd53vINkGuDIhh6ISCml3CoNyHbZz7GPudoMLAAQkSnAACDdPmeAD0Rkg4jc7nJNH2NMHoC9bqMjiuoKp9PwxsYcLnhyNX/4OItLzurLx/89i3svHEpwoF/8c62UT/KL34riI4KJCw9iX3s10/3OgZAY2LwMhl7Uc8EppVT3a6VzCKbF/mLgaRHJBLYCm4AG+9w0Y0yuiCQDH4rILmPM2k6/uJWA3w7Qv3//043dL204VMwv3tnB5uwSxqXH8McbJzJpQLynw1JKdYJfJNNg1U5ntVczHRwO42+AdX+BisVWp0SllPJNOUA/l/10INe1gDGmDLgNQEQEOGAvGGNy7fVxEXkTq9nIWuCYiKQYY/JEJAU43tqLG2OeA54DmDx5csskXrnILanm1+/t4u3MXJKjQnhy4TiunpDWemd5pZRX8pvfjQYnRbIvv7L9QpNuA2c9ZL7UM0EppZR7rAOGikiGiAQD1wPLXQuISKx9DuC7wFpjTJmIRIhIlF0mArgY2GaXWw7cam/fCrzt5vfRa9U1OHlq1R4ueHI1/952lLtnD+GTH83imknpmkgr5WP8qmZ62bpsiirriI9oY4D75BHQ/zzY8Fc474cQ4Dd/ayilehFjTIOI3A28jzU03gvGmO0icod9fgkwEvibiDQCO4Dv2Jf3Ad60KqsJBF42xrxnn1sM/FNEvgMcBhb21HvqTQoravnBSxv5+kARl41N4SdzR5Aep9OAK+Wr/CaZbhrRY19+BfER7bRDm/xteOO7cGA1DL6gZ4JTSqluZoxZCaxscWyJy/aXwNBWrtsPjGvjnoXAnO6N1L/sOlrGd5euJ7+8lqevH89V41v2C1VK+Rq/qXptGtGj3XbTAKOuhLB4WP9iD0SllFLKX3yw/SjX/PEL6hud/PP752oirVQv4TfJdGpsGCGBAe0PjwcQGAITboRd70JZXs8Ep5RSqtcyxvDMx3u5/e8bGJIcyfK7pzOuX6ynw1JKdRO/SaYdAcKgpMj2J25pMuk2MI2w6R/uD0wppVSvVVPfyA+XZfLEB3u4anwqr37/XPpEh3o6LKVUN/KbZBpgcFJE+2NNN0kYDBkzYeNScDa6PzCllFK9ztHSGhYu+ZJ3tuTy/y4dzlPXjSc0yOHpsJRS3cyvkukhyZHkFFdTU9+JBHnyt6E0G7JWuT8wpZRSvcqmw8Vc8cxn7M+v4M83T+bOWUOwR0hRSvUyfpVMD06KxBjY39F40wAjLoOIZFj/gvsDU0op1Wu8ty2P6577itCgAN64cxoXjurj6ZCUUm7k1mRaRC4Vkd0ikiUii1o5HyMiK0Rks4hsF5Hb3BlP84genWnq4QiCiTfD3g+gJNudYSmllOoljDE89s5OhiRF8vZd0xneN8rTISml3MxtybSIOIBngbnAKOAGERnVothdwA5jzDhgFvCky4xc3S4jMQIROh7Ro8nEW8EY2Pg3d4WklFKqFzlUWMWRkmpumNKv7QnClFK9ijtrpqcAWcaY/caYOmAZcFWLMgaIEqshWSRQBDS4K6DQIAf94sI7VzMNEDcAhlxoJdON9e4KSymlVC/xaVYBANOHJnk4EqVUT3FnMp0GuLaPyLGPuXoGa0rbXGArcK8xxtnyRiJyu4isF5H1+fn5ZxTU4KSIztdMg9URseIo7Hmv47JKKaX82md780mLDWNggk4PrpS/cGcy3Vq3ZdNi/xIgE0gFxgPPiEj0KRcZ85wxZrIxZnJS0pn9tT8kOZL9BZU0OluG0oahF0N0mnZEVEop1a5Gp+GLfYVMH5KoI3co5UfcmUznAP1c9tOxaqBd3Qa8YSxZwAFghBtjYnBSJHUNTo4UV3fuAkcgTLwF9n0MRQfcGZpSSikftiWnhPKaBqYPTfR0KEqpHuTOZHodMFREMuxOhdcDy1uUOQzMARCRPsBwYL8bY3IZ0aO88xdNvAXEARv+6p6glFJK+bzP7fbS5w1O8HAkSqme5LZk2hjTANwNvA/sBP5pjNkuIneIyB12sceA80RkK/AR8IAxpsBdMYFVMw2w73gnxppuEp0Kw+da04s31LkpMqWUUr7s070FnJUaTUJkiKdDUUr1oEB33twYsxJY2eLYEpftXOBid8bQUlxEMAkRwWSdTidEgEm3wa53YNcKGH2Ne4JTSinlk6rqGth4uJhvT8vwdChKqR7mVzMgNhmcHMm+zg6P13zRBRDbH9a/6J6glFJK+az/HCiivtFoe2ml/JB/JtNJkWTlV2BMJ0f0AAgIgEnfgoOfQv4et8WmlFLK93y+t4DgwADOHhjv6VCUUj3ML5PpIcmRlFTVU1R5mu2fJ9wMAYHaEVEppdRJPssq4OyBcYQGOTwdilKqh/llMj04KQLg9NtNRybDqPmw7nk48Gn3B6aUUt1ERC4Vkd0ikiUii1o5Hycib4rIFhH5WkRG28f7icgnIrJTRLaLyL0u1zwiIkdEJNNe5vXke/JWx8tr2HW0nGlDtImHUv7IL5PppuHx9uWfxogeTeb9BuIGwis3QG5mt8allFLdQUQcwLPAXGAUcIOIjGpR7EEg0xgzFrgFeNo+3gD8tzFmJDAVuKvFtb8zxoy3l5UovsgqBGDGEJ1CXCl/5JfJdGpMGGFBjtOvmQYIj4eb34SwWPjHNVCQ1e3xKaXUGZoCZBlj9htj6oBlwFUtyozCGpIUY8wuYKCI9DHG5BljNtrHy7GGNk3rudB9z6d7C4gND2JU6ikT+Cql/IBfJtMBAcKgpIjTH9GjSUwa3PyWtf33+VB6pLtCU0qp7pAGZLvs53BqQrwZWAAgIlOAAVgz1TYTkYHABOA/LofvtpuGvCAica29uIjcLiLrRWR9fn7+Gb0Rb2eM4fOsAqYNTsQRoFOIK+WP/DKZBntEj67UTDdJHAI3/QuqS+AfC6CqqNtiU0qpM9RaVtdy+KLFQJyIZAL3AJuwmnhYNxCJBF4H/ssYU2Yf/hMwGBgP5AFPtvbixpjnjDGTjTGTk5J6d9OHffkVHC2r0SHxlPJjfptMD0mO5EhJNdV1jV2/SeoEuOEVKDoALy2E2jNIzpVSqvvkAP1c9tOBXNcCxpgyY8xtxpjxWG2mk4ADACIShJVIv2SMecPlmmPGmEZjjBP4M1ZzEr/22V5r0t7p2vlQKb/lt8l087TiXW3q0SRjBnzjBcjdCK/eBA21HV9jDBxYC699C166FhrrzywGpZQ62TpgqIhkiEgwcD2w3LWAiMTa5wC+C6w1xpSJiAB/AXYaY37b4poUl92rgW1uewc+4rOsAgYkhNMvPtzToSilPMRvk+kTI3p0Q23yyMvhyj/A/k/gze+Ds43a7upi+PKP8MzZsPQK2LsK9r6vsyoqpbqVMaYBuBt4H6sD4T+NMdtF5A4RucMuNhLYLiK7sEb9aBoCbxpwM3BBK0PgPS4iW0VkCzAbuK+n3pM3qm908tX+Ih0STyk/F+jpADxlYGI4AQL7zqTdtKsJN1ntpj/8OYTGwuW/AxGrFvrIRlj/F9j2OjTUQPrZMH8JnDUfXr4WVv8vjF0IYa325VFK+TERuRxYaTet6DR72LqVLY4tcdn+EhjaynWf0Xqba4wxN59ODL3d5uwSKmobmKHJtFJ+zW+T6ZBAB/3jw7s21nRbpv0Qqgrh86cgNAbiM2DdX+DoFgiKgHE3wORvQ8rYE9dc8r+wZAas+Q1c+r/dF4tSqre4HnhaRF4HXjTG7PR0QMryWVYBInDu4ARPh6KU8iC/TaahG0b0aM2Fj5xIqAGSz4LLnoQx10JoK2OQ9h0DE2+Gr//PSrQTh3RvPEopn2aMuUlEooEbgBdFxAAvAq/Y40ArD/lsbwFj02KIDQ/uuLBSqtfy2zbTYLWbPlBQSaOz5YhRZ0AErnga5j0B3/4AfvA5nP3d1hPpJhf8HALDrCYiSinVgj003etYk6+kYHX+2ygi93g0sF5kX34F+eWd6EBuK6+pZ1N2ibaXVkqdXjItIgF2DUmvMDgpkrpGJ9lFVd174wAHTPke9D/HSq47EpkMM+6H3Sth/5rujUUp5dNE5AoReRP4GAgCphhj5gLjgB95NLheIr+8lque+Zz5z35OQUXnEur/7C+i0Wl0fGmlVMfJtIi8LCLRIhIB7AB2i8iP3R+a+w3uzhE9ztTUOyG2P7z/YNujgSil/NFC4HfGmLHGmN8YY44DGGOqgG97NrTe4ckPdlNT30hBRS13/H0DtQ0dP4M/yyogNCiASQO047hS/q4zNdOj7J8Y52P1DO+PNWySzxtijzXd7e2muyIoFC58FI5tg01/93Q0Sinv8TDwddOOiITZ03xjjPnIU0H1FtuOlPLq+mxuPW8gTywcx/pDxTz4xjaMab/532dZBUzJSCAk0NFDkSqlvFVnkukgezas+cDbxph6Tp2W1ifFhAeRGBniHTXTAGddDf2mwse/hJqyjssrpfzBa4DrsHiN9jF1howxPPbODuLCg/nhnKFcMS6VH84Zyusbc3hu7f42r8srrSbreIUOiaeUAjqXTP8fcBCIANaKyACg12R6g5MivKNmGqz21Zf+L1Tmw2e/7bi8UsofBBpj6pp27G0dPqIbvLftKP85UMT9Fw0jJiwIgP+aM5R5Y/qy+L1dfLTzWKvXfZ5VCKCdD5VSQCeSaWPM740xacaYecZyCGvmq15hSHIk+/IrO/xJr8ekTYKx11szJRYf9HQ0SinPyxeRK5t2ROQqoMCD8fQKNfWN/O+/dzK8TxTXn92v+XhAgPDkwvGclRrND1/ZxO6jp44++NnefBIjgxnRN6onQ1ZKeanOdEC81+6AKCLyFxHZCFzQA7H1iMFJkZRW11NQUddx4Z4y5yFrRJAPH/Z0JEopz7sDeFBEDotINvAA8H0Px+TzXvj8ANlF1Tx0xSgCHSf/UxgW7ODPt0wmIiSQ7yxdR6HLCB/GGD7LKuS8wYkEBHRitCalVK/XmWYe37Y7IF4MJAG3AYvdGlUPGuJNI3o0iUmDaffCjrfg0JeejkYp5UHGmH3GmKnAKKwO4ecZY7I8HZcvO15ew7MfZ3HhyD5tNtVIiQnjuVsmk19eyw/+sZG6BqvZ+u5j5RRU1OqQeEqpZp1Jppv+9J6HNZXtZpdjPq9peDyvaTfd5Lx7ICoV3v8JOJ0dl1dK9VoichlwJ3CfiDwkIg95OiZf9sT7u6lrdPLTy0a2W258v1ge/8ZYvj5YxM/e2mrVSu+1WthM1/bSSilbZ5LpDSLyAVYy/b6IRHFyz3KflhIdSniww7tqpgGCI6ypyXM3wZZXPR2NUspDRGQJcB1wD1ZFxkJggEeD8mHbjpTy2oYcvnXeQDISIzosf9X4NO65YAj/XJ/DXz47wGdZBQxKiiA1NqwHolVK+YLOJNPfARYBZ9uTBARjNfXoFQIChEHeNKKHqzELIXUifPQo1FV6OhqllGecZ4y5BSg2xjwKnAv06+Aa1QpjDL9YsYP48GDumTO009fdd+Ew5o7uy/+s3MkXWYVaK62UOklnRvNwAunAz0TkCawH+xa3R9aDhiRFsj/fC5PVgAC49FdQngfPzbZG+Kgs9HRUSqmeVWOvq0QkFagHMjwYj89aufUoXx8s4v6LhxEdGtTp6wIChCevHceolGjqGp2aTCulTtKZ0TwWA/diTSW+A/ihiPyqMzcXkUtFZLeIZInIojbKzBKRTBHZLiJrTif47jI4KZIjJdVU1jZ44uXb138qfOMFCImy2k//dgS8dhvsX61tqZXyDytEJBb4DbARa9z/VzwZkC+qqW/kf1fuZETfKK4/u/9pXx8eHMhfbj2bu2cP4fxhSW6IUCnlqwI7UWYeMN6uoUZElgKbgJ+0d5GIOIBngYuAHGCdiCw3xuxwKRML/BG41BhzWESSu/QuzlDTiB4HCioZnRbjiRDaN/oaazlqTzW+eRlsfwNiB8DEm2H8jRCd6ukolVLdTEQCgI+MMSXA6yLyDhBqjCn1bGS+5y+fHeBISTUvf/ccHF0c0q5vTCg/umR4N0emlPJ1nWkzDRDrst3ZbHMKkGWM2W/P2LUMuKpFmW8CbxhjDgMYY4538t7dymtH9Gip72iY+2v4792w4HmI7W9NPf67s+Dl62HHcqjRf2OV6i3sSownXfZrO5tId/TLoIjEicibIrJFRL4WkdEdXSsi8SLyoYjstddxZ/gWe8Txshqe/SSLi0f14TxtoqGU6madqZn+FbBJRD7B6kl+Ph3UStvSgGyX/RzgnBZlhgFBIrIaiAKeNsb8reWNROR24HaA/v1P/+e5jgxMiMARIN43okdbgkJh7EJrKdxn1VZnvgx7/g3igNQJMGgmZMyEfudY5ZVSvuoDEbkGq+KhU1O1duaXQeBBINMYc7WIjLDLz+ng2kVYNeWL7SR7EdYkMl7t8fd3U9/o5MF57Q+Fp5RSXdFhMm2MecVOds/GSqYfMMYc7cS9W/sdreU/BIHAJGAOEAZ8KSJfGWP2tIjhOeA5gMmTJ3f7vN/BgQEMiA/3/prp1iQMtobQm/1TOPwVHFgD+9fAZ0/Bp09CYKiVUA+aCRmzIGUcODrzN5RSykvcD0QADSJSg/VsNcaY6Hauaf5lEEBEmn4ZdE2mR2FVlmCM2SUiA0WkDzConWuvAmbZ1y8FVuPlyfS2I6X8a0MO3z9/EAM7MRSeUkqdrjazKhGZ2OJQjr1OFZFUY8zGDu6dw8nDN6UDua2UKTDGVAKVIrIWGAfsoYcNSor0nZrp1jiCIGOGtVzwM6gpg0NfwIG1VoL90S+AX0BIDKRPgr5jrcQ6ZRzEZVgjhyilvI4xJqoLl3Xml8HNwALgMxGZgjV2dXoH1/YxxuTZceV5qp/L6XjpP4cID3Zw1wVDPB2KUqqXaq+K8sl2zhnggg7uvQ4YKiIZwBHgeqw20q7eBp4RkUCs8avPAX7XwX3dYkhyJGv2HKeh0UmgoxcklqHRMPxSawGoyIeDa63k+shG+PJZcNZb54KjoO8YO7m2k+zEYVaCrlRvYQzUV9tLpb2ugrqqE9vNS7XLurr1YxNvgXHXuz1sETm/9bdj1rZ3WWuXtNhfDDwtIpnAVqyO5Q2dvLZd7m6a11m1DY28uyWPi0f1Oa2h8JRS6nS0mUwbY2afyY2NMQ0icjfwPuAAXjDGbBeRO+zzS4wxO0XkPWAL1qyKzxtjtp3J63bV4KQI6hsN2cXVnZoVy+dEJp0YFQSgoQ7yd0LeFsjbDEe3wMalVrIAEBAEMekQN8AaNSS2P8QNtNaxAyAyGaTXzCqvPMkYaKw/kag2VLsksW0ls6eR9LoeO13isGYjDQqzl/ATa+mxP7p/7LIditWEYwPtV2h0+MugMaYMewIuERHggL2Et3PtMRFJsWulU4BWO427u2leZ63enU9ZTQNXTUjzVAhKKT/g1sazxpiVwMoWx5a02P8N1vipHtU0PN6uvLLemUy3FBh8opkHN1vHnI1Wh8a8zXB8OxQfgpLDsHslVOa3uD7USqyjUyGyD0QkWevI5JO3wxMgwNHjb0+dIacTGmpOLPXV9rrGSkpPOlbtkgTXtJ4MN7gmtjUnthvs+5kujJkeEOSS3IZCkEvSG9nXWrsmwoFhEBxuX+OSFAe32G8+HuEVv84YY65w3ReRfsDjHVzW4S+D9tCkVfZoS98F1hpjykSkvWuXA7di1WrfivXrotd6O/MICRHBzNARPJRSbqQ90WxnpcYQHRrIhzuPMXdMiqfD8YwAByQNsxYWnnyurspKrEvsBLv4oLVdftTq+Fhx3EqYWpIAK6EOi4PQWAiLbXsdEmUlRMFNCY29HRjmH226jQFng1VL21hrrRtqobHuxNLQtN10vsY+VnuirOu6ocberrH266tPHD9p7ZoI11j366rA0BPJa5DLEhhqJ7mhVrIaGOqSvIadnPQ2J7YtkmTX8l6Q6HpIDjC6vQKd+WUQGAn8TUQasToXfqe9a+1bLwb+KSLfAQ5zyoPCe5TV1LNq53FuOLtf72i6p5TyWppM24IDA7j4rL68v/0otQ2NhARqbepJgsMheYS1tMYYqKuwkuqK41BxzKrNrjhm7deUQHWJtZ+/29qvKaPTTTFdaxUdQVatpCPYGpkkIMg61nw8CAICraV523HiWECQve/AHhjhxHuwNk7eN06r1t40Wsmus8GquW3abj7eeCIZbt6vP1GusWldd2LdWGcdb6w70Ya9u4gDAkPsJcxeh568Do05sR8UaieynV27JMnNCW6If/zh04NE5A+c+B8lABiP1XmwXR39MmiM+RIY2tlr7eOFWKMveb33th2lrsGpTTyUUm7X3mgeNxlj/mFvTzPGfO5y7m5jzDM9EWBPmjemL//akMMXWYXMHuH1ndS9i4hVsxwSZQ3X1xnORqgts5LsmhKoLbdqTutcOoc1dxCrPNFkoLHOrr2ttxLQpuS1vhoay+xjDS6JbxtJrdNl+vjm9t9y6r7IyQm5OFz2XY45Ak9N2ANDTk3oHcEt/iBo+mMg2D4WaCWljiD7+uATS9P9HCEn9gNdth3BJxJlbV7TW6x32W4AXnF9HqvWvZ15hAEJ4UzoF+vpUJRSvVx7NdP3A/+wt/8AuA6V922g1yXT04YkEhUSyMqteZpM94QAh9X8I8wnJlFTylP+BdQYYxrBmpBFRMKNMV3oUekfjpXV8MW+Qu65YCiiHaWVUm7W3u+x0sZ2a/u9Qkigg4tG9eGDHceob+xChyillOp+H2FNatUkDFjloVh8worNuRgD88enejoUpZQfaC+ZNm1st7bfa8wdk0JpdT1f7Cv0dChKKQUQaoxpnlHK3g73YDxe763MI4xNj2FQUqSnQ1FK+YH2kukRIrJFRLa6bDftD++h+HrcjKGJRIYE8u+teZ4ORSmlwJodtrmZnYhMAloZOkcBZB2vYNuRMq4arx0PlVI9o7020yN7LAovEhrkYM7IZN7ffpRfzh+tQyoppTztv4DXRKRp4pQU4DrPhePd3s48QoDAFeP8dIhTpVSPay9TDALSjTGHXBegP718SL25o1Morqrnq/1Fng5FKeXnjDHrgBHAD4A7gZHGmA2ejco7GWN4OzOXaUMSSY4K9XQ4Sik/0V4y/RRQ3srxavtcrzVreBLhwQ5WbtOmHkopzxKRu4AIY8w2Y8xWIFJE7vR0XN5o4+ESDhdVaRMPpVSPai+ZHmiM2dLyoDFmPTDQbRF5gdAgB7NHJPP+tqM0OnttX0ullG/4njGmpGnHGFMMfM9z4XivtzOPEBIYwCVn9fF0KEopP9JeMt3eb2Rh7ZzrFS4bk0JhZR1fH9CmHkopjwoQl8GSRcQBBHswHq9U3+jknS15XDiqD1GhfjvVvFLKA9pLpteJyCm1HyLyHaDXt9ebNTyJ0KAAVuqoHkopz3of+KeIzBGRC4BXgH97OCav89neAooq65ivTTyUUj2svY6E/wW8KSI3ciJ5noxVI3K1m+PyuPDgQGYPT+a97Ud55MqzcAT0ynlqlFLe7wHgdqwOiAJswhrRQ7l4K/MIseFBzByW5OlQlFJ+ps2aaWPMMWPMecCjwEF7edQYc64x5mjPhOdZ88akkF9ey4ZDxZ4ORSnlp4wxTuArYD9WhcYcYKdHg/IylbUNfLD9GPPGpBAcqMOZKqV6VodD3BljPgE+6YFYvM7sEcmEBFpNPaZkxHs6HKWUHxGRYcD1wA1AIfAqgDFmtifj8kYf7jhGdX2jNvFQSnmE/gnfjsiQQGYOS+Lf2/Jw6qgeSqmetQurFvoKY8x0Y8wfgEYPx+SV3so8QlpsGJMHxHk6FKWUH+rVk690h3ljUvhgxzE2ZRczaYDWTiulesw1WDXTn4jIe8AyrDbTykVBRS2f7i3g9vMHEaB9W5TyL04n1JZBdRFUFUFVYSuLfS5lLMz9tVvC0GS6A3NGJhPsCGDl1qOaTCuleowx5k2sTuARwHzgPqCPiPwJeNMY84En4/MW727Jo9FptImHUr6ovhqqS6CmpPV1bZm9lFtLjct2bTnUtTa3oC0gEMITTiwh0W57G5pMdyAqNIjzhyXy7615/HTeSK35UEr1KGNMJfAS8JKIxAMLgUWAJtNYTTxG9I1ieN8oT4eiVO9kDDTWQ2Mt1FVBXQXUV1nb9ZVQV3nqtmuZ5u3Kk5eaEmioaf+1g6MgxGUJjYaYNHs/2l6iTk6aw+Pt5DkKpGdyNk2mO2Hu6BRW7TzO5pwSJvTXNnlKKc8wxhQB/2cv7RKRS4GnAQfwvDFmcYvzMcA/gP5Y/xY8YYx5UUSGY3d2tA0CHjLGPCUij2DNvphvn3vQGLPyzN5V1x0qrGTT4RIWzR3hqRBUb+ZshJpScARBYKi19hRjrJrYpmYL1UVWgmsarThNo9XkwTSCcZ441lh/Inl1TWjr7SS3rsrabqiFxjqrvLP+xHbT/ukKDIWgcAiOhOBwezsColNPbIfFQmhsi3WctQ6LsxJlh2+kqb4RpYddOKoPQQ7h39uOajKtlPJ69iyJzwIXATlYk3AtN8bscCl2F7DDGHOFiCQBu0XkJWPMbmC8y32OAG+6XPc7Y8wTPfE+OvJ2Zi4icOW4VE+HonxBU3JcXWw1IagqhMrjUHEcKgtctvOtparQSkybiAOCwiAwBALtdVDYiURbHBAQYK8d1loC7O2AE8ea9tsq31jXor2vvd2VpNZVUISV2AZH2Nv2fkSS9V4cQfYSDAEu283HQ+zE2OXa4MgTyXFwxIntAMeZxepjNJnuhJiwIKYPSWTl1jx+MncE0kM/GyilVBdNAbKMMfsBRGQZcBXgmkwbIMqeqjwSKAIaWtxnDrDPGHPI/SGfvuWbc5kyMJ7U2DBPh6I8rbYCjm6B3EzI32XV3Da3vS211rVlbV8fFAGRSVZiGZcB/aZARLJVQ+pssJojNNRAfc2J7eb9aruW2AkNdS61xc6Ta4ybaouN89RjzeWdVuLa1GQhPgPSJ53YD7ObMITFQWDwyYl4c5Lukrg7gq2kNzDMStyVW2gy3Ulzx6Twyb+2sPVIKWPTYz0djlJKtScNyHbZzwHOaVHmGWA5kAtEAdfZE8S4uh5r+nJXd4vILcB64L+NMafMaiUit2PN2kj//v27+h7alV9eS9bxCq6dp008/I5r4pyXaa0L9mD9fQiEJ0JEotV0IDoNks860XTAtVlBeMKJBDo4wiNvRfUOmkx30sWj+vBggLBy61FNppVS3q61n89aDpZ/CZAJXAAMBj4UkU+NMWUAIhIMXAn8xOWaPwGP2fd6DHgS+PYpL2TMc8BzAJMnT3bLIP2Z2SUA2vTOlzkbTx6ZoXkpPXm/eQSHUsjfc3LiHJUCKeNh9AJrnToeovp67j0pv6TJdCfFhgdz3pBE/r0tjwcuHa5NPZRS3iwH6Oeyn45VA+3qNmCxMcYAWSJyABgBfG2fnwtsNMYca7rAdVtE/gy844bYO2XT4WICA4TRqTGeCsE/NdRB8QEo2AtlR+yOanXQ2HBi2+my3dQBrrbs1KS5rqITLyguIzdEQvwgTZyV19Fk+jTMG92XRW9sZXtuGaPT9AGulPJa64ChIpKB1YHweuCbLcocxmoT/amI9AGGA/tdzt9AiyYeIpJijMmzd68Gtrkh9k7JzC5hREoUYcH+1dGpx1QVWQlzgV0TXJhlrYsOWG18WyMBdoe1YGuM36bOa8ERVjIcGgsx/ewhzmJOHvKs5VBnofY6KELb+iqv59ZkuqOhmVzKnQ18hdVm71/ujOlMXHxWX3761jb+vS1Pk2mllNcyxjSIyN3A+1jP3xeMMdtF5A77/BKsZhp/FZGtWM1CHjDGFACISDjWSCDfb3Hrx0VkPNZv7AdbOd8jGp2GLTmlXD1BJ2rpsuoSKM2GksNQkm1vH7K2Sw5bHfiaOIIhYQj0OQtGzYfEYZA4FGL7n0ieHUF+N4KDUk3clkx3cmimpnK/xnroe7X4iGDOHZTAmxuPcNfsIYQHa8W+Uso72eM/r2xxbInLdi5wcRvXVgEJrRy/uZvD7JKs4xVU1DYwvl+sp0PxHg32cGrVLadULjp5XXHMSpZbjmwRGGYlx7H9IHWClTwnDoPEIRA7QBNlpdrhzmywM0MzAdwDvA6c7cZYus0P5wzluue+ZPG/d/GLq0Z7OhyllPI7mdnWACLj+8d6NhBPK8uF3Sth17tw4NO2xyEOiYHwOGv0iph+MOA8K3GO6Wcn0P2tc9oXSKkucWcy3eHQTCKShtXu7gLaSaZ7YpilzpqSEc9t52XwwucHuPSsvpw3JNGj8SillL/ZdLiEmLAgMhL8bDgzYyB/N+x6x0qgczdax+MHwznftzrnnTStsst4xEopt3FnMt2ZoZmewmqn19je6Bg9MczS6fjxJcP5ZPdxfvyvLbx/3/lEhmhzD6WU6imZ2SWM6xdLQIAf1KQ6GyFn3YkEusjuI5o2CeY8BCMut5pjaK2yUh7jziywM0MzTQaW2Yl0IjBPRBqMMW+5Ma4zFhbs4ImFY1m45Ev+592d/GrBGE+HpJRSfqGitoE9x8q5+KxeNiRabbk9eoY9gkahvV2YZQ0xFxAEGefDuXfD8HkQneLpiJVSNncm0x0OzWSMyWjaFpG/Au94eyLdZNKAeL43YxD/t3Y/c0f35fxhSZ4OSSmler0tOSU4DUzw5fbS1SVwYA0c/MxqtlGwF8pd6prEYU0jnTgMhl4EKeNgyIXWcHJKKa/jtmS6k0Mz+bT7LhrGqp3HeOB1q7lHdGiQp0NSSqlerWnmw/G+NBOts9Ga8nrfR5C1CnLWW2M1B0dC0ggYNMsaaq5pyLm4DG3nrJQPcWtj346GZmpx/FvujMUdQoMcPHnteBb88XMeW7GD3ywc5+mQlFKqV8s8XEJGYgRxEV6ebJbl2cnzR7D/E6guBsSatW/6fVZNc/pka3xmpZRP055zZ2h8v1h+MGswz36yj7lj+nLBiD6eDkkppXolYwybskuY7u2jKL19F2z6h7Ud2QeGzYUhc2DQbIg4ZfhupZSP02S6G/xwzlBW7TjOote38uF98cSEa02DUkp1t9zSGvLLa717spb9a6xEeuItMOX71qyBOtKGUr2aTnjfDUICHTx57TgKK+t4ZMV2T4ejlFK9UubhEsCLOx86nfDBz6zJUOb+BvqO1kRaKT+gyXQ3GZ0Ww12zh/DmpiO8v/1ou2Wr6hp4f/tRfvzaZh741xaM8fjQ2Uop5fU2HS4mODCAEX2jPR1K67a+Bke3WOM/B4V6OhqlVA/RZh7d6O7ZQ1i14xg/fXMrZw+MJ96lg8zR0hpW7TzGRzuP8fm+QuoanAQHBlDX4GTumL7MGp7swciVUsr7ZWaXMDo1muBAL6wHqq+Gjx+zhrEb/Q1PR6OU6kGaTHej4MAAnlg4jque/Yyfv72NH8wczKqdx1i18xjbjpQB0D8+nBvP6c9FI/swvn8sc55cw59W79NkWiml2lHf6GTrkVJumjrA06G07j9LoDQb5v8RArww2VdKuY0m091sVGo0P7xgKE9+uId3t+QhAhP7x/H/Lh3ORSP7MCQ5Etep0787YxCPvbODDYeKmTQgzoORK6WU99qVV05tg9M7Ox9WFsKnv4Vhl1qzFCql/Iom027wg1mDcRpIjQ1l9ohkEiND2ix7/dn9+MPHe1myZh9/vmVyD0aplFK+IzO7GPDSzodrfg11FXDho56ORCnlAfpblBsEOgK498KhLJzcr91EGiAiJJBbzx3IhzuOsedYeQ9FqJRSvmXT4RISI0NIiw3r/ptXFsBfLoY374DG+tO7tnAfrP+LNRRe8ojuj00p5fU0mfYC3zpvIGFBDpas2efpUJRSyitlZpcwvl/sSc3kukX5MfjrZZC7CTa/Aq99CxrqOn/9qkfAEQKzHuzeuJRSPkOTaS8QFxHMDVP6szwzl5ziKk+Ho5TqBUTkUhHZLSJZIrKolfMxIrJCRDaLyHYRuc3l3EER2SoimSKy3uV4vIh8KCJ77XWPdPQoqapjf0Fl9zfxKMuzEumSw3DTGzD3cdj1Drx6E9TXdHz94a9g53KYdi9E6ey3SvkrTaa9xHdnZADw/KcHPByJUsrXiYgDeBaYC4wCbhCRUS2K3QXsMMaMA2YBT4pIsMv52caY8cYY184ci4CPjDFDgY/sfbfLzC4BYEJ3dj4szYG/zoPyPLjpdciYAed8Hy77Lex9H5Z90xruri3GWBO0RPaF8+7uvriUUj5Hk2kvkRobxvwJaSxbd5iiytP4iVEppU41Bcgyxuw3xtQBy4CrWpQxQJRY7SYigSKgoYP7XgUstbeXAvO7LeJ2ZGaXIAJjuyuZLj4EL86z2krf/CYMOO/EubO/A1c+A/s+hpevhbrK1u+x4y3IWQcX/BSCI7onLqWUT9Jk2ovcMXMQNfVO/vq51k4rpc5IGpDtsp9jH3P1DDASyAW2AvcaY5z2OQN8ICIbROR2l2v6GGPyAOx1jwyQn5ldwrDkKCJDumEAqqL9VtOOmhK45S3oN+XUMhNvhquXwMHP4KWFUNuic3hDHax6FJJHwfgbzzwmpZRP02TaiwxJjuLiUX1Y+uUhKmo7qiBSSqk2tdZLz7TYvwTIBFKB8cAzItI0T/c0Y8xErGYid4nIaQ2eLCK3i8h6EVmfn59/WoGfErQxzZ0Pz1jhPnjxMmsYu1tXQNqktsuOux4W/NlqF/2Pa6Cm7MS59X+B4gNw0S8gwHHmcSmlfJom017mB7MGU1pdz7KvD3s6FKWU78oB+rnsp2PVQLu6DXjDWLKAA8AIAGNMrr0+DryJ1WwE4JiIpADY6+Otvbgx5jljzGRjzOSkpKQzeiMHC6soqao/886H+butph2NdXDrO9a03x0Z8w34xgtwZAP8/WqoLrGWNb+GQbNgyIVnFpNSqlfQZNrLTOgfx7mDEvjzp/upbWj0dDhKKd+0DhgqIhl2p8LrgeUtyhwG5gCISB9gOLBfRCJEJMo+HgFcDGyzr1kO3Gpv3wq87dZ3wYnJWsafSTJ9bIfVtMM44VvvQt/Rnb/2rPlw7d8gbzP87SpY9bCVUF/0GHT3MH1KKZ+kybQX+sGswRwrq+XtTS0rkpRSqmPGmAbgbuB9YCfwT2PMdhG5Q0TusIs9BpwnIluxRuZ4wBhTAPQBPhORzcDXwLvGmPfsaxYDF4nIXuAie9+tNh0uISLYwdDkqK7dIH+3lUgHBMJtK7s2scqIy+D6l+H4TtjwV6sJSMrYrsWjlOp1dDpxLzRjaCJnpUazZO0+rpmUjiNAaz+UUqfHGLMSWNni2BKX7VysWueW1+0HWm0DYYwpxK7N7imZ2SWMTY/t2nOwvgZeu81q1/ytdyFhcNcDGXYxfHMZfP40XPDzrt9HKdXraM20FxIR7pw1hP35lXyw/ainw1FKKY+oqW9kR25Z15t4fPQoHN8O8/90Zol0k8EXwC1vQ0zLgVGUUv5Mk2kvdenovgxMCOdPa/ZhTMtO+Eop1fttzy2lwWm6NllL1kfw1R9hyu0w9KJuj00ppZpoMu2lHAHC92cOZktOKV/sK/R0OEop1eM2HS4ButD5sLIQ3voBJI2whq9TSik30mTaiy2YmEZyVAh/Wr3P06EopVSP25RdQlpsGMlRoZ2/yBhY8UOoLoZrnoegMPcFqJRSaDLt1UICHXxnegafZRXwxb4CT4ejlFI9KvNwyenXSm/8G+x6B+Y8BH3HuCUupZRypcm0l/vmOf3pEx3Cjc//h/tfzSS7qMrTISmllNsdL6/hSEn16bWXLsiC9xZBxkyYepfbYlNKKVeaTHu5qNAg3v+v87l9xiDe3ZrHnCfX8OiK7RRW1Ho6NKWUcpvMpvbSnU2mG+vhje9CYAhcvQQC9J83pVTP0KeND4gND+Yn80ay+sezuHpCGku/OMjM36zm6VV7qaxt8HR4SinV7TKzSwgMEEanxXTugtW/gtxNcMXTEJ3q3uCUUsqFW5NpEblURHaLSJaILGrl/I0issVevhCRVicKUJaUmDB+/Y2xfHDf+UwbksDvVu1h5m8+YekXB6lrcHo6PKWU6jaZ2SWMTIkmNMjRceGDn8Onv4UJN8Goq9wfnFJKuXBbMi0iDuBZYC4wCrhBREa1KHYAmGmMGYs1te1z7oqnNxmSHMX/3TyZN+48j8FJkTy8fDsX/nYNb27K0aRaKeXzGp2GzdklTOhM58PqEnjz+xCfAZf+2t2hKaXUKdxZMz0FyDLG7DfG1AHLgJOqDIwxXxhjiu3dr4B0N8bT60zsH8ey26fy4m1nEx7s4L5XN3Pe4o954v3dHCmp9nR4SinVJVnHK6isa+xce+mVP4KyXFjwZwiJdHtsSinVUqAb750GZLvs5wDntFP+O8C/WzshIrcDtwP079+/u+LrFUSE2cOTmTk0iTV78vnHV4d4dnUWf1ydxQUjkrlp6gDOH5pEQIB4OlSllOqUzGyrjqXDZHrLP2HrazD7Z5A+2f2BKaVUK9yZTLeWvbU6L7aIzMZKpqe3dt4Y8xx2E5DJkyfr3NqtCAgQZo9IZvaIZHKKq3jl68O8ui6bVTuP0z8+nG+e059rJ/cjPiLY06EqpVS7HAEBTOwfS0ZiRNuFGmrh3/8P+k2FGff3XHBKKdWCO5PpHKCfy346kNuykIiMBZ4H5hpjdN7sbpAeF86PLxnBvXOG8d72o/zjq0Ms/vcufvvBHuaN6cu1Z/fjnIwEHFpbrZTyQt+YlM43JnXQ6i9rlTXL4fk/hoBOdFJUSik3cWcyvQ4YKiIZwBHgeuCbrgVEpD/wBnCzMWaPG2PxS8GBAVw5LpUrx6Wy51g5L311iDc2HuGtzFySo0K4fGwqV4xLYXy/WEQ0sVZK+ZCtr0F4Igya6elIlFJ+zm3JtDGmQUTuBt4HHMALxpjtInKHfX4J8BCQAPzRTuYajDHa8M0NhvWJ4tGrRrNo7kg+2nWMFZtz+cdXh3jh8wP0jw/ninEpXDkujeF9ozwdqlJKta+2Ana/BxNuBEeQp6NRSvk5d9ZMY4xZCaxscWyJy/Z3ge+6MwZ1srBgB5ePTeXysamU1dTz/rajLN+cy5I1+3n2k30M7xPFleNTuXxsCgMS2mmvqJRSnrJ7JTRUw+hveDoSpZRybzKtvFt0aBALJ/dj4eR+FFTUsnJrHsszc/nN+7v5zfu7GZQYwfnDkpgxNJGpgxKICNGvi1LKC2z9F8T0g37tDRCllFI9Q7MjBUBiZAi3nDuQW84dyJGSaj7YfpS1e/J5dV02f/3iIEEOYfKAeGYMS+T8oUmMSonW4faU8mIicinwNFYzu+eNMYtbnI8B/gH0x/q34AljzIsi0g/4G9AXcALPGWOetq95BPgekG/f5kH7F8ieU1UE+z6Cc++CALdO4quUUp2iybQ6RVpsGLdNy+C2aRnUNjSy/mAxa/fks3ZvAY+/t5vH39tNYmQw04ckct6QRKYMjGdAQrh2YlTKS7jMQHsR1shK60RkuTFmh0uxu4AdxpgrRCQJ2C0iLwENwH8bYzaKSBSwQUQ+dLn2d8aYJ3rw7Zxsx1vgbNAmHkopr6HJtGpXSKCDaUMSmTYkkZ8Ax8tq+HRvAWv35vPp3gLeyrRGO0yOCuHsjHimDIzn7IHxDO8bpUPvKeU5zTPQAohI0wy0rsm0AaLE+is4EijC6gSeB+QBGGPKRWQn1iRcrtd6ztbXIXE49B3j6UiUUgrQZFqdpuToUK6ZlM41k9JxOg1Z+RV8faCIdQeLWHegiHe35AEQFRrI5AFxzQn2WakxhAXrWLBK9ZDOzED7DLAca/z/KOA6Y4zTtYCIDAQmAP9xOXy3iNwCrMeqwS5u+eJum7W29Agc+hxmPwj6S5hSyktoMq26LCBAGNYnimF9orhp6gAAcoqrmpPrrw8U8cluq2mlI0AYmhzJuPRYxqTHMDY9hhF9owkO1DaPSrlBZ2agvQTIBC4ABgMfisinxpgyABGJBF4H/qvpGPAn4DH7Xo8BTwLfPuWF3DVr7fY3rJcefU233VIppc6UJtOqW6XHhZMeF86CidbsZYUVtWw4VMzWI6Vszinlgx1HeXW9VWEW7AhgREoUY9Ks5Pqs1BiG9okkJFBrsJU6Q52ZgfY2YLExxgBZInIAGAF8LSJBWIn0S8aYN5ouMMYca9oWkT8D77gp/tZt/RekToSEwT36skop1R5NppVbJUSGcPFZfbn4rL4AGGPIKa62k+sStuaUsjwzl5f+cxiwarAHJ0Uwom80I1KiGJkSzci+0fSJDtEOjkp1Xocz0AKHgTnApyLSBxgO7LfbUP8F2GmM+a3rBSKSYrepBrga2ObG93CygizIy4RL/rfHXlIppTpDk2nVo0SEfvHh9IsPZ96YFACcTsPBwkp25JWxK6+cXUfL2HComOWbT1SkxYYHMaJvFCP6RjO0TyRDkiIZkhxJQmSIp96KUl6rkzPQPgb8VUS2YjULecAYUyAi04Gbga0ikmnfsmkIvMdFZDxWM4+DwPd77E1t+5cV5lkLeuwllVKqMzSZVh4XECAMSopkUFIkl489cby0up7dR63kemdeGTvzynl1XTbV9Y3NZeLCgxhsJ9ZDkiMZnGwl2mmxYToOtvJrnZiBNhe4uJXrPqP1NtcYY27u5jA7xxiricfA6RCd4pEQlFKqLZpMK68VExbElIx4pmTENx9zOg25pdVkHa9gX36ltT5ewQc7jrFs3YnBC0ICAxiQEM7AhAgGJkactJ0SHaqJtlK+JG8zFO6F8+72dCRKKXUKTaaVTwkIkOZOjrOGn3yuqLKOffkVZB2v4EBBJQcKKjlYWMmaPfnUNpwY8Ss4MID+8VZy3S8+jH5x4aTHhTU3P4nUadOV8i7b/gUBQTDySk9HopRSp9CsQfUa8RHBxEdYk8a4cjoNR8tqOFhYyaHCKg7aSfahwiq+3FdAZV3jSeVjw4NOSrDT48JIiQkjNTaU1JgwYsODtDOkUj3F6YRtb8CQCyE8vuPySinVwzSZVr1eQICQGhtGamwY57UYUcsYQ3FVPdlFVeQUV5NdXNW8vftYOR/tOk5dw0nzWBAaFGDdLyaMlJhQ+96h9IkOpW9MKH2jQ4kJ04RbqW5x+EsoOwIX/cLTkSilVKs0mVZ+TUTsGu1gxvWLPeW802koqKwlr6SG3JJqcktryCupJre0mtySGtbsySe/ohbTYlqK0KAA+kTbCbadZCdHhdjrUJKiQkiOCiFCm5Qo1b5t/4KgcBg+19ORKKVUq/RfcqXaERAgJEdZCXBryTZAXYOTY2U1HC2r4WhpjbVdau0fL6slM7uEo9trTqnhBogIdpAcHUpSZAhJ0VaCnRwVSmJkMIlRISRFhpAYGUJCZDBBDp0tUvmZxnrY/paVSAdHeDoapZRqlSbTSp2h4MCA5s6LbTHGUFJVz7FyK8E+Xl5Lfnktx8trrO2yWnbklrG6rOaUNtxNYsKCrCQ7MqQ50W6qVU9oWkcGEx8RQmxYkI5Yonzf/tVQXQRjFno6EqWUapMm00r1ABEhLiKYuIhgRvRtv2xlbQMFFbUUVNSSX15HQUUthRV1zccKKqzEu6CilvKahlbvESAQFx7cnGzHhVuvHRceRHxEMLHhwcRHBFnrcOt8VGigJuDKu2x9DUJjYfAcT0eilFJt0mRaKS8TERJIREggAxI6/lm7rsFJcVUdhRV1FFXWUVhZS1Fl03YdRRV1FFfVsb+ggqJD9ZRU1dHgNK3eK0Cs2u/Y8GB7HUSsy35ceBAx4UFEhwYRE2Yt0fY6NMjR3R+D8nd1VbDrXRi9AAKDPR2NUkq1SZNppXxYcOCJjo6dYYyhvLaBksp6iqrqKK60ku2iyjpKq+spqaqnpNpKuosq69ifX0lJVR1lbdSAu8ZhJdmBxIQFERVqJdpRoYFEhQYSHRpEdGigyzErKY8MDSQyxFocWiuuXO19H+oqtImHUsrraTKtlB8RETuxDaJ/QtttvFtqaHRSVtNAaXU9pdX1lNnr0up6ympOHCurbrCT8joOF1VRXmMdq2s8tfNlSxHBDiLtRDsyJLA5EY+0a+qj7LVrAh7psh8ebK1DgwJ0WMLeYOu/ILIvDJjm6UiUUqpdmkwrpToU6Ahobn/dFTX1jZTXNFBWU2+tq+upqG2gwj5WUdtAeY21X1F74lheaQ2VdrmKuoZThiBsTYBARLCVeIeHOOxE29GccEeEOKx1sIOwFvvhdtmwIAfhwdbxsGBrW0dT6UHVJbD3Azj7uxCgTYiUUt5Nk2mllNuFBjkIDXKQFBXS5XsYY6iqa6SytoFyO8F23a6qa6CittFeW+cq7fKVtQ0cKamhus46VlXbQFV9Y6eS8yZBDrGTbCvh/s6MDG48Z0CX349qx653oLEOxnzD05EopVSHNJlWSvkEEWnunJncDfczxlBT76SyroHqukYq6xqotJPxqrpGqusaqaqz9qvrGqmqbzpmnU/oYi296oTQGBh5JaRO9HQkSinVIU2mlVJ+SUQIC3YQFqzNCLzOyCusRSmlfIA2AlRKKaWUUqqLNJlWSimllFKqi9yaTIvIpSKyW0SyRGRRK+dFRH5vn98iItpATimlukEnnr8xIrJCRDaLyHYRua2ja0UkXkQ+FJG99jqup96PUkp5K7cl0yLiAJ4F5gKjgBtEZFSLYnOBofZyO/And8WjlFL+opPP37uAHcaYccAs4EkRCe7g2kXAR8aYocBH9r5SSvk1d9ZMTwGyjDH7jTF1wDLgqhZlrgL+ZixfAbEikuLGmJRSyh905vlrgCixZriJBIqAhg6uvQpYam8vBea79V0opZQPcGcynQZku+zn2MdOtwwicruIrBeR9fn5+d0eqFJK9TKdebY+A4wEcoGtwL3GGGcH1/YxxuQB2OvuGKVQKaV8mjuT6dbm8205RUJnymCMec4YM9kYMzkpKalbglNKqV6sM8/WS4BMIBUYDzwjItGdvLb9F9cKEKWUH3FnMp0D9HPZT8eqATndMkoppU5PZ56ttwFv2M3ssoADwIgOrj3W1BTPXh9v7cW1AkQp5U/cOWnLOmCoiGQAR4DrgW+2KLMcuFtElgHnAKVNPyG2ZcOGDQUicqgL8SQCBV24zlv4cvy+HDto/J7my/G3FntPzEHemefvYWAO8KmI9AGGA/uBknauXQ7cCiy21293FIg+s32WL8fvy7GDxu9pLePv8JnttmTaGNMgIncD7wMO4AVjzHYRucM+vwRYCcwDsoAqrJqSju7bpWoOEVlvjJnclWu9gS/H78uxg8bvab4cv6di7+Tz9zHgryKyFatpxwPGmAI77lOutW+9GPiniHwHKxlf2IlY9Jntg3w5fl+OHTR+T+tK/G6dTtwYsxIrYXY9tsRl22ANz6SUUqobdeL5mwtc3Nlr7eOFWLXZSimlbDoDolJKKaWUUl3kT8n0c54O4Az5cvy+HDto/J7my/H7cuye5uufncbvOb4cO2j8nnba8YvV0kIppZRSSil1uvypZloppZRSSqlu1euTaRG5VER2i0iWiCzydDynS0QOishWEckUkfWejqcjIvKCiBwXkW0ux+JF5EMR2Wuv4zwZY3vaiP8RETli/zfIFJF5noyxLSLST0Q+EZGdIrJdRO61j/vE599O/L7y+YeKyNcistmO/1H7uE98/t5En9s9R5/ZnqPPbM/qzmd2r27mISIOYA9wEdZEBOuAG4wxOzwa2GkQkYPA5KYhq7ydiJwPVAB/M8aMto89DhQZYxbb/zDGGWMe8GScbWkj/keACmPME56MrSNiTaKRYozZKCJRwAZgPvAtfODzbyf+a/GNz1+ACGNMhYgEAZ8B9wIL8IHP31voc7tn6TPbc/SZ7Vnd+czu7TXTU4AsY8x+Y0wdsAy4ysMx9WrGmLVAUYvDVwFL7e2lWP+zeaU24vcJxpg8Y8xGe7sc2Amk4SOffzvx+wR7JsEKezfIXgw+8vl7EX1u9yB9ZnuOPrM9qzuf2b09mU4Dsl32c/Ch/9A2A3wgIhtE5HZPB9NFfZpmtrTXyR6OpyvuFpEt9k+KXvmTmysRGQhMAP6DD37+LeIHH/n8RcQhIplY02x/aIzxyc/fw/S57Xm94TvrE8+MJvrM9ozuemb39mRaWjnma+1aphljJgJzgbvsn7RUz/oTMBgYD+QBT3o0mg6ISCTwOvBfxpgyT8dzulqJ32c+f2NMozFmPJAOTBGR0R4OyRfpc1udKZ95ZoA+sz2pu57ZvT2ZzgH6ueynA7keiqVL7FnKMMYcB97E+gnU1xyz21Y1tbE67uF4Tosx5pj9P5wT+DNe/N/Abvf1OvCSMeYN+7DPfP6txe9Ln38TY0wJsBq4FB/6/L2EPrc9z6e/s770zNBntnc402d2b0+m1wFDRSRDRIKB64HlHo6p00Qkwm7Uj4hEYE39u639q7zScuBWe/tW4G0PxnLamv6nsl2Nl/43sDtT/AXYaYz5rcspn/j824rfhz7/JBGJtbfDgAuBXfjI5+9F9LnteT79nfWhZ4Y+sz2oO5/ZvXo0DwB7SJanAAfwgjHmfzwbUeeJyCCsWg2AQOBlb49fRF4BZgGJwDHgYeAt4J9Af+AwsNAY45UdRtqIfxbWz1UGOAh8v6k9lTcRkenAp8BWwGkffhCrDZvXf/7txH8DvvH5j8XqrOLAqqj4pzHmFyKSgA98/t5En9s9R5/ZnqPPbM/qzmd2r0+mlVJKKaWUcpfe3sxDKaWUUkopt9FkWimllFJKqS7SZFoppZRSSqku0mRaKaWUUkqpLtJkWimllFJKqS7SZFr1GiLyKxGZJSLzRWSRh2JYLSKTPfHaSinlS/SZrXoLTaZVb3IO1vicM7HGvlRKKeW99JmtegVNppXPE5HfiMgW4GzgS+C7wJ9E5KFWyiaJyOsiss5eptnHHxGRv4vIxyKyV0S+Zx8X+/7bRGSriFzncq//Zx/bLCKLXV5moYh8LSJ7RGSGW9+8Ukr5GH1mq94m0NMBKHWmjDE/FpHXgJuB+4HVxphpbRR/GvidMeYzEekPvA+MtM+NBaYCEcAmEXkXOBdrJqdxWDNsrRORtfax+cA5xpgqEYl3eY1AY8wUexa3h7GmKFVKKYU+s1Xvo8m06i0mAJnACGBHO+UuBEaJSNN+tIhE2dtvG2OqgWoR+QSYAkwHXjHGNALHRGQNVm3KTOBFY0wVQIupRt+w1xuAgWf4vpRSqjfSZ7bqNTSZVj5NRMYDfwXSgQIg3DosmcC59oPWVUBrx+0HtWlR1gBC66SV8k1q7XUj+v+YUko102e26o20zbTyacaYTGPMeGAPMAr4GLjEGDO+lYcywAfA3U079oO9yVUiEioiCcAsYB2wFrhORBwikgScD3xt3+fbIhJu38f1J0OllFKt0Ge26o00mVY+z35gFhtjnMAIY0x7Pxn+EJgsIltEZAdwh8u5r4F3ga+Ax4wxucCbwBZgM9ZD//8ZY44aY94DlgPr7RqVH3X3+1JKqd5In9mqtxFj2vrVQyn/ISKPABXGmCc8HYtSSqn26TNbeROtmVZKKaWUUqqLtGZaKaWUUkqpLtKaaaWUUkoppbpIk2mllFJKKaW6SJNppZRSSimlukiTaaWUUkoppbpIk2mllFJKKaW6SJNppZRSSimluuj/A2yfFwMSdfnIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(num_epochs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=False, figsize=(12, 4))\n",
    "ax0, ax1 = axes.ravel()\n",
    "\n",
    "ax0.plot(xs, tr_loss, label='train loss')\n",
    "ax0.plot(xs, dev_loss, label='dev loss')\n",
    "ax0.legend()\n",
    "ax0.set_xlabel('# epoch')\n",
    "ax0.set_ylabel('CE loss')\n",
    "\n",
    "ax1.plot(xs, tr_metric, label='train acc')\n",
    "ax1.plot(xs, dev_metric, label='dev acc')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('# epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should evaluate the model performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-84f028fc8fec>:29: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "def nn_test(data, labels, params):\n",
    "    h, output, cost = forward_prop(data, labels, params)\n",
    "    accuracy = accuracy = (np.argmax(output,axis=1) == np.argmax(labels,axis=1)).sum() * 1. / labels.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "accuracy = nn_test(testData, testLabels, params)\n",
    "print('Test accuracy: {0}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Adversarial Examples for Neural Networks\n",
    "\n",
    "It has been seen that many classifiers, including neural networks, are highly susceptible to what are called adversarial examples -- small perturbations of the input that cause a classifier to misclassify, but are imperceptible to humans. For example, making a small change to an image of a stop sign might cause an object detector in an autonomous vehicle to classify it as an yield sign, which could lead to an accident.\n",
    "\n",
    "In this part, we will see **how to construct adversarial examples for neural networks**, and you are given a 3-hidden layer perceptron trained on the MNIST dataset for this purpose.\n",
    "\n",
    "Since we are interested in constructing the countersample rather than the original classification task, we do not need to worry too much about the design of the neural network and the processing of the data (which are already given). The parameters of the perceptron can be loaded from fc\\*.weight,npy and fc\\*.bias.npy. The test dataset can be loaded from X_test.npy and Y_test.npy. Each image of MNIST is 28×28 pixels in size, and is generally represented as a flat vector of 784 numbers. It also includes labels for each example, a number indicating the actual digit (0 - 9) handwritten in that image. \n",
    "\n",
    "**Enjoy practicing generating adversarial examples and have fun!**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define some functions for later computing.\n",
    "\n",
    "(a) **[10 points]** Please realize the following functions: \n",
    "\n",
    "relu: The relu function is calculated as:\n",
    "\n",
    "$$\n",
    "relu(x)=max(0,x)\n",
    "$$\n",
    "\n",
    "relu_grad: The relu_grad is used to compute the gradient of relu function as:\n",
    "\n",
    "$$\n",
    "relu\\_grad(x)=(1(x>0),0(x \\leq 0))\n",
    "$$\n",
    "\n",
    "one_hot: In the implementation of the cross entropy loss, it is much convenient if numerical labels are transformed into one-hot labels. For example, numerical label 6 -> one-hot label [0,0,0,0,0,0,1,0,0,0]. Accordingly, the cross entropy loss can be written as follow:\n",
    "\n",
    "$$\n",
    "cross\\_entropy(y,\\hat y)=-\\sum_{k=1}^K y_k \\log \\hat y_k\n",
    "$$\n",
    "\n",
    "where $\\hat{y}$ is the softmax outputs from the model for the training example, $y$ is the one-hot (ground-truth) label, and the subscript refers to the element of $y$ at the coordinate $k$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    '''\n",
    "    Input\n",
    "        x: a vector in ndarray format\n",
    "    Output\n",
    "        relu_x: a vector in ndarray format,\n",
    "        representing the ReLu activation of x.\n",
    "    '''\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    relu_x = np.maximum(x,0)\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return relu_x\n",
    "\n",
    "def relu_grad(x):\n",
    "    '''\n",
    "    Input\n",
    "        x: a vector in ndarray format\n",
    "    Output\n",
    "        relu_grad_x: a vector in ndarray format,\n",
    "        representing the gradient of ReLu activation.\n",
    "    '''\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    if x.all()>0:\n",
    "        relu_grad_x = 1\n",
    "    else:\n",
    "        relu_grad_x = 0\n",
    "        \n",
    "    ### END YOUR CODE\n",
    "    return relu_grad_x\n",
    "\n",
    "def cross_entropy(y, y_hat):\n",
    "    '''\n",
    "    Input\n",
    "        y: an int representing the class label\n",
    "        y_hat: a vector in ndarray format showing the predicted\n",
    "           probability of each class.\n",
    "           \n",
    "    Output\n",
    "        the cross entropy loss. \n",
    "    '''\n",
    "    log_likelihood = -np.log(y_hat)\n",
    "    return log_likelihood[y]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the structure and some utility functions of our multi-layer perceptron.\n",
    "\n",
    "\n",
    "The neural net is a fully-connected multi-layer perceptron with three hidden layers. The hidden layers contains 2048, 512 and 512 hidden nodes respectively. We use ReLU as the activation function at each hidden node. The last intermediate layer’s output is passed through a softmax function, and the loss is measured as the cross-entropy between the resulted probability vector and the true label.\n",
    "\n",
    "\n",
    "    x: the input image vector with dimension 1x784.\n",
    "    y: the true class label of x.\n",
    "    zi: the value of the i-th intermediate layer before activation, with dimension 1x2048, 1x512, 1x512 and 1x10 for i = 1, 2, 3, 4.\n",
    "    hi: the value of the i-th intermediate layer after activation, with dimension 1x2048, 1x512 and 1x512 for i = 1, 2, 3.\n",
    "    p: the predicted class probability vector after the softmax function, with dimension 1x10.\n",
    "    Wi: the weights between the (i - 1)-th and the i-th intermediate layer. For simplicity, we use h0 as an alias to x. Each Wi has dimension li_1 x li, where li is the number of nodes in the i-th layer. For example, W1 ha dimension 784x2048.\n",
    "    bi: the bias between the (i - 1)-th and the i-th intermediate layer. The dimension is 1 x li.\n",
    "\n",
    "(b) **[20 points]** Please realize the forward propogation and the gradient calculation:\n",
    "\n",
    "**[10 points]** The forward propagation rules are as follows.\n",
    "$$\n",
    "z^i = h^{i-1} \\cdot W^i + b^i, i = 1, 2, 3, 4.\n",
    "$$\n",
    "\n",
    "$$\n",
    "z^i = h^{i-1} \\cdot W^i + b^i, i = 1, 2, 3.\n",
    "$$\n",
    "\n",
    "$$\n",
    "p = Softmax(z^4)\n",
    "$$\n",
    "\n",
    "**[10 points]** The gradient calculation rules are as follows.\n",
    "\n",
    "Let L denote the cross entropy loss of an image-label pair (x, y). We are interested in the gradient of L w.r.t. x, and move x in the direction of (the sign of) the gradient to increase L. If L becomes large, the new image x_adv will likely be misclassified.\n",
    "\n",
    "We use chain rule for gradient computation. Again, let h0 be the alias of x. We have:\n",
    "$$\n",
    "\\frac{\\delta L}{\\delta x} =  \\frac{\\delta L}{\\delta z^4} \\frac{\\delta z^4}{\\delta h^3} \\prod_{i=1}^{3} \\{ \\frac{\\delta h^i}{\\delta z^i} \\frac{\\delta z^i}{\\delta h^{i-1}} \\}\n",
    "$$\n",
    "\n",
    "The intermediate terms can be computed as follows.\n",
    "\n",
    "$$\n",
    "\\frac{\\delta L}{z^4} = p - one\\_hot(y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{z^i}{h^{i-1}} = (W^i)^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\delta h^i}{\\delta z^i}=relu\\_grad(z^i)\n",
    "$$\n",
    "\n",
    "(c) **[10 points]** Please generate the adversarial examples based on the gradient.\n",
    "\n",
    "We begin with deriving a simple way of constructing an adversarial example around an input (x, y).\n",
    "Supppose we denote our neural network by a function f: X $\\rightarrow$ {0,...,9}.\n",
    "Suppose we want to find a small perturbation $\\Delta$ of x such that the neural network f assigns a label different from y to x+$\\Delta$. To find such a $\\Delta$, we want to increase the cross-entropy loss of the network f at (x, y); in other words, we want to take a small step $\\Delta$ along which the cross-entropy loss increases, thus causing a misclassification. We can write this as a gradient ascent update, and to ensure that we only take a small step, we can just use the sign of each coordinate of the gradient. The final algorithm is this:\n",
    "\n",
    "$$\n",
    "x_{adv} = x + \\epsilon \\cdot sign (\\nabla L(f(x), y))\n",
    "$$\n",
    "\n",
    "where L is the cross-entropy loss, and it is known as the **Fast Gradient Sign Method (FGSM)**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron():\n",
    "    '''\n",
    "    This class defines the multi-layer perceptron we will be using\n",
    "    as the attack target.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.eps = 0.1\n",
    "    \n",
    "    def load_params(self, params):\n",
    "        '''\n",
    "        This method loads the weights and biases of a trained model.\n",
    "        '''\n",
    "        self.W1 = params[\"fc1.weight\"]\n",
    "        self.b1 = params[\"fc1.bias\"]\n",
    "        self.W2 = params[\"fc2.weight\"]\n",
    "        self.b2 = params[\"fc2.bias\"]\n",
    "        self.W3 = params[\"fc3.weight\"]\n",
    "        self.b3 = params[\"fc3.bias\"]\n",
    "        self.W4 = params[\"fc4.weight\"]\n",
    "        self.b4 = params[\"fc4.bias\"]\n",
    "        \n",
    "    def set_attack_budget(self, eps):\n",
    "        '''\n",
    "        This method sets the maximum L_infty norm of the adversarial\n",
    "        perturbation.\n",
    "        '''\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        This method finds the predicted probability vector of an input\n",
    "        image x.\n",
    "        \n",
    "        Input\n",
    "            x: a single image vector in ndarray format\n",
    "        Ouput\n",
    "            self.p: a vector in ndarray format representing the predicted class\n",
    "            probability of x.\n",
    "            \n",
    "        Intermediate results are stored as class attributes.\n",
    "        You might need them for gradient computation.\n",
    "        '''\n",
    "        W1, W2, W3, W4 = self.W1, self.W2, self.W3, self.W4\n",
    "        b1, b2, b3, b4 = self.b1, self.b2, self.b3, self.b4\n",
    "        \n",
    "        self.z1 = np.matmul(x,W1)+b1\n",
    "        #######################################\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        self.z2 = np.matmul(relu(self.z1),W2)+b2\n",
    "        self.z3 = np.matmul(relu(self.z2),W3)+b3\n",
    "        self.z4 = np.matmul(relu(self.z3),W4)+b4\n",
    "        self.p = softmax(self.z4)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        #######################################\n",
    "        return self.p\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        This method takes a single image vector x and returns the \n",
    "        predicted class label of it.\n",
    "        '''\n",
    "        res = self.forward(x)\n",
    "        return np.argmax(res)\n",
    "\n",
    "\n",
    "    def gradient(self,x,y):\n",
    "        ''' \n",
    "        This method finds the gradient of the cross-entropy loss\n",
    "        of an image-label pair (x,y) w.r.t. to the image x.\n",
    "        \n",
    "        Input\n",
    "            x: the input image vector in ndarray format\n",
    "            y: the true label of x\n",
    "            \n",
    "        Output\n",
    "            grad: a vector in ndarray format representing\n",
    "            the gradient of the cross-entropy loss of (x,y)\n",
    "            w.r.t. the image x.\n",
    "        '''\n",
    "        \n",
    "        #######################################\n",
    "        ### YOUR CODE HERE\n",
    "        y = np.array([y])\n",
    "        grad_z4 = self.p - one_hot_labels(y)\n",
    "        grad1 = np.matmul(grad_z4, self.W4.T)\n",
    "        grad2 = np.multiply(grad1, relu_grad(self.z3))\n",
    "        grad3 = np.matmul(grad2, self.W3.T)\n",
    "        grad4 = np.multiply(grad3, relu_grad(self.z2))\n",
    "        grad5 = np.matmul(grad4, self.W2.T)\n",
    "        grad6 = np.multiply(grad5, relu_grad(self.z1))\n",
    "        grad = np.matmul(grad6, self.W1.T)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        #######################################\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def attack(self,x,y):\n",
    "        '''\n",
    "        This method generates the adversarial example of an\n",
    "        image-label pair (x,y).\n",
    "        \n",
    "        Input\n",
    "            x: an image vector in ndarray format, representing\n",
    "               the image to be corrupted.\n",
    "            y: the true label of the image x.\n",
    "            \n",
    "        Output\n",
    "            x_adv: a vector in ndarray format, representing\n",
    "            the adversarial example created from image x.\n",
    "        '''\n",
    "        \n",
    "        #######################################\n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        grad = self.gradient(x, y)\n",
    "        x_adv = x + self.eps*np.sign(grad)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        #######################################\n",
    "        \n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the test data and the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./X_test.npy\")\n",
    "Y_test = np.load(\"./Y_test.npy\")\n",
    "\n",
    "params = {}\n",
    "param_names = [\"fc1.weight\", \"fc1.bias\",\n",
    "               \"fc2.weight\", \"fc2.bias\",\n",
    "               \"fc3.weight\", \"fc3.bias\",\n",
    "               \"fc4.weight\", \"fc4.bias\"]\n",
    "\n",
    "for name in param_names:\n",
    "    params[name] = np.load(\"./\"+name+'.npy')\n",
    "    \n",
    "clf = MultiLayerPerceptron()\n",
    "clf.load_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the image data are loaded correctly. Let's visualize the first image in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of Number 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x175001a2ac0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = X_test[0], Y_test[0]\n",
    "print (\"This is an image of Number\", y)\n",
    "pixels = x.reshape((28,28))\n",
    "plt.imshow(pixels,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model is loaded correctly. The test accuracy may be 97.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.976\n"
     ]
    }
   ],
   "source": [
    "nTest = 1000\n",
    "Y_pred = np.zeros(nTest)\n",
    "for i in range(nTest):\n",
    "    x, y = X_test[i], Y_test[i]\n",
    "    Y_pred[i] = clf.predict(x)\n",
    "acc = np.sum(Y_pred == Y_test[:nTest])*1.0/nTest\n",
    "print (\"Test accuracy is\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) **[5 points]** Please generate an adversarial example and check the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of Number 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17501357340>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPj0lEQVR4nO3dYYhd5Z3H8d/PceokthGjq5ukkhoR2SS6qQ664iouZcXqCy2mqxFKBDEKVSoUXHERfSm765aiS2W6DY2LaxXaUBFZK1KJfaE4kaiJ0VWvY5ImJDF5ESUZa8b/vpibMtW5z5ncc889Z+b5fmC4M+d/zz3/3Lm/3Dv3uc95HBECMPedUHcDAPqDsAOZIOxAJgg7kAnCDmTixL4e7MQTY3BwsJLbHh8fL7X/0NBQZccuc9s5q/N+bfLvtKi3iPB020uF3fbVkn4qaUDSf0XEQ6nrDw4OatmyZWUO2dHbb79dav8yfRUdu6p/81xX5/3a5N9pt4/1rl/G2x6Q9J+SvitpuaQ1tpd3e3sAqlXmb/aLJb0fEa2I+JOkX0m6rjdtAei1MmFfImnnlJ93tbf9BdvrbI/aHp2YmChxOABllAn7dG8CfOWztxExEhHDETE8MDBQ4nAAyigT9l2Szpry8zcl7S7XDoCqlAn7a5LOtX227a9JuknSM71pC0CvdT30FhFHbd8p6XlNDr2tj4htPevsOC1fXt9AQNGxi4ZK6uy9SNkhzTLK3q91KvM7L7Nvq9XqWCs1zh4Rz0l6rsxtAOgPPi4LZIKwA5kg7EAmCDuQCcIOZIKwA5no63z28fHx2sZGZ/NYeJVjtnPZXL1f+j7FFcDsQtiBTBB2IBOEHcgEYQcyQdiBTPR16G1oaKixZ5dt8tBalftXPSRZ5RBXmWOX/X3PxqE7ntmBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHciEI76yiEt1B7MrO1iTTzvc5FNFF8l16m+T/11FOi3ZzDM7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZmFXj7GXGPps8L7tIlWO+TR5vrlOT75ei3jqNs5c6eYXtMUmfSJqQdDQihsvcHoDq9OJMNf8QER/34HYAVIi/2YFMlA17SPqd7c221013BdvrbI/aHi15LAAllH0Zf1lE7LZ9hqQXbL8TEZumXiEiRiSNSNVOhAGQVuqZPSJ2ty/3Sdoo6eJeNAWg97oOu+2TbX/j2PeSrpK0tVeNAeitMi/jz5S00fax2/mfiPjfMs1UOdbd5HH0InWee302a/LvtA5dhz0iWpL+toe9AKgQQ29AJgg7kAnCDmSCsAOZIOxAJvq6ZHOdyg7DXHXVVR1rq1evTu67f//+ZP2zzz5L1p999tlk/eOPO89D2rFjR3LfOqdyMjQ2varuF57ZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IRKNOJd3kaajPP/98x9rixYv72MlXHT58uGPtpJNOqvTY27ZtS9ZXrFhRyb4z2X/v3r0da6+88kpy36effjpZb+rU4FarpSNHjrBkM5Azwg5kgrADmSDsQCYIO5AJwg5kgrADmWjUfPYmz29+4IEHOtbOO++85L4ffPBBsn7OOeck60Xz5efPn99VTZJOO+20ZP3AgQPJ+gUXXJCsp6xcuTJZX7RoUbI+MDDQ9e3fc889yX3nIp7ZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IRF/H2YeGhrRs2bJKbrvqMfrU/OeiudFFDh48mKxv2LAhWV+wYEHH2g033JDct2je9vnnn5+slzE+Pp6sf/TRR8l60fn0U3bu3Nn1vnXr9rFe+Mxue73tfba3Ttm20PYLtt9rX57a1dEB9M1MXsb/UtLVX9p2r6QXI+JcSS+2fwbQYIVhj4hNkr78OvM6ScdeW26QdH1v2wLQa92+QXdmROyRpPblGZ2uaHud7VHboxMTE10eDkBZlb8bHxEjETEcEcNFExcAVKfbsO+1vUiS2pf7etcSgCp0G/ZnJK1tf79W0m970w6AqhSOs9t+UtKVkk63vUvSA5IekvS07Vsl7ZD0/V40U+VYedlz0td5nvAyx3711VeT9aVLlybrhw4d6vrYZa1duzZZv/TSS5P1jRs3dqyNjY0l923qeeHLKAx7RKzpUPpOj3sBUCE+LgtkgrADmSDsQCYIO5AJwg5koq9TXMfHxxt7uui5ONTSdAsXLkzW77///mTdnnZl4j/btGlTx1rZIcU6H8epx2qr1epY45kdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMNGrJ5jIYJ599br755mS9aBy+aKz8ww8/PO6e+iX1eC0aw6/sVNIA5gbCDmSCsAOZIOxAJgg7kAnCDmSCsAOZcET07WDz5s2L1JLNTT6dM7pz4YUXdqytX78+ue+7776brN9yyy3J+ubNm5P1uSoipp3ozzM7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZaNR548suq5xS5Rh92c8HzOXPF1x++eUda4ODg8l9P/3002T9jTfe6Kqn2a6y88bbXm97n+2tU7Y9aPuPtre0v6453oYB9NdMXsb/UtLV02z/SUSsan8919u2APRaYdgjYpOkg33oBUCFyrxBd6ftN9sv80/tdCXb62yP2h4tcSwAJXUb9p9JOkfSKkl7JD3c6YoRMRIRwxEx3OWxAPRAV2GPiL0RMRERX0j6uaSLe9sWgF7rKuy2F0358XuStna6LoBmKBxnt/2kpCslnW57l6QHJF1pe5WkkDQm6faZHGxoaEip+exVqnM97bLHrnMcvujYqfnqUvrc759//nly30cffTRZP3r0aLI+W1X1eZPCsEfEmmk2/6KrowGoDR+XBTJB2IFMEHYgE4QdyARhBzLRqCWb6xweq3J6bdXKTBsu65JLLknWV69e3bH28ssvJ/d94oknkvXZ/DurA8/sQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kIpslm8uOuaaOXeVtl1W2tyuuuCJZf+SRR5L1I0eOdKzdfnt6ZnTZU0VX+TtrMpZsBjJH2IFMEHYgE4QdyARhBzJB2IFMEHYgE40aZy9jLo91Vzlv+5RTTknWn3rqqWR9yZIlyfqOHTs61q699trkvnUu4T2bx+EZZwcyR9iBTBB2IBOEHcgEYQcyQdiBTBB2IBONOm98kSrHVcsoOw+/yjHdE05I/38+MjKSrBeNo+/atStZv+OOOzrWqj6nfZ3z2ev6jECr1epYK3xmt32W7d/b3m57m+0ftbcvtP2C7ffal6d20ziA/pjJy/ijkn4cEX8j6e8k/dD2ckn3SnoxIs6V9GL7ZwANVRj2iNgTEa+3v/9E0nZJSyRdJ2lD+2obJF1fUY8AeuC43qCz/S1J35b0qqQzI2KPNPkfgqQzOuyzzvao7dGJiYmS7QLo1ozDbvvrkn4t6e6IODTT/SJiJCKGI2J4YGCgmx4B9MCMwm57UJNBfyIiftPevNf2onZ9kaR91bQIoBcKp7jatib/Jj8YEXdP2f5vkg5ExEO275W0MCLuKbityubTlh3GqfI01mWVGaZZunRpsj42Npasb926NVm/6667kvWXXnqpY63J00xna2+tVktHjhyZdorrTMbZL5P0A0lv2d7S3nafpIckPW37Vkk7JH3/eBoG0F+FYY+IP0ia9n8KSd/pbTsAqsLHZYFMEHYgE4QdyARhBzJB2IFMzKoprnVOWUzdft1j/IsXL+5Ye/zxx7vq6ZiHH344Wd+/f3+p269SmcfLbD6VdCc8swOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kIlZNc5e51h3mX2rngu/YsWKjrUDBw4k9y2qHz58OFnftm1bsp5S9/1W5bHL/Nuq+gwAz+xAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSi8LzxvTRv3rxYtmxZ1/tXOc7eZBdddFGy/thjj3WszZ8/P7lv0Xnhb7rppmS9aJy9zO+lyePwRaqcD9/teeN5ZgcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOF89ltnyXpcUl/LekLSSMR8VPbD0q6TdKxE4ffFxHPpW5rfHy8svHHqsdk65xLf9tttyXrrVar62MvWLAgWT/77LOT9So/p9HkcfTZaCYnrzgq6ccR8brtb0jabPuFdu0nEfHv1bUHoFdmsj77Hkl72t9/Ynu7pCVVNwagt47rb3bb35L0bUmvtjfdaftN2+ttn9phn3W2R22PlmsVQBkzDrvtr0v6taS7I+KQpJ9JOkfSKk0+80+7KFhEjETEcEQMl28XQLdmFHbbg5oM+hMR8RtJioi9ETEREV9I+rmki6trE0BZhWG3bUm/kLQ9Iv5jyvZFU672PUnp6VMAajWTd+Mvk/QDSW/Z3tLedp+kNbZXSQpJY5JuL7qhoaEhVTXFtWpVDgOVve2VK1d2rL3zzjvJfW+88cZk/dChQ1311AtVDqdW/Viqsrdue5/Ju/F/kDTd/NjkmDqAZuETdEAmCDuQCcIOZIKwA5kg7EAmCDuQiUadSrrKZW6rHCevc/xfmruna65znL3otuv+nadEBKeSBnJG2IFMEHYgE4QdyARhBzJB2IFMEHYgE30dZ7e9X9JHUzadLunjvjVwfJraW1P7kuitW73sbWlE/NV0hb6G/SsHt0ebem66pvbW1L4keutWv3rjZTyQCcIOZKLusI/UfPyUpvbW1L4keutWX3qr9W92AP1T9zM7gD4h7EAmagm77attv2v7fdv31tFDJ7bHbL9le0vd69O119DbZ3vrlG0Lbb9g+7325bRr7NXU24O2/9i+77bYvqam3s6y/Xvb221vs/2j9vZa77tEX3253/r+N7vtAUn/J+kfJe2S9JqkNRHRiLMB2B6TNBwRtX8Aw/YVkj6V9HhErGxv+1dJByPiofZ/lKdGxD83pLcHJX1a9zLe7dWKFk1dZlzS9ZJuUY33XaKvf1If7rc6ntkvlvR+RLQi4k+SfiXpuhr6aLyI2CTp4Jc2XydpQ/v7DZp8sPRdh94aISL2RMTr7e8/kXRsmfFa77tEX31RR9iXSNo55eddatZ67yHpd7Y3215XdzPTODMi9kiTDx5JZ9Tcz5cVLuPdT19aZrwx9103y5+XVUfYpzs/VpPG/y6LiAslfVfSD9svVzEzM1rGu1+mWWa8Ebpd/rysOsK+S9JZU37+pqTdNfQxrYjY3b7cJ2mjmrcU9d5jK+i2L/fV3M+fNWkZ7+mWGVcD7rs6lz+vI+yvSTrX9tm2vybpJknP1NDHV9g+uf3GiWyfLOkqNW8p6mckrW1/v1bSb2vs5S80ZRnvTsuMq+b7rvblzyOi71+SrtHkO/IfSPqXOnro0NcySW+0v7bV3ZukJzX5su5zTb4iulXSaZJelPRe+3Jhg3r7b0lvSXpTk8FaVFNvf6/JPw3flLSl/XVN3fddoq++3G98XBbIBJ+gAzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE/8Pp3zGz3iX7qQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Output pixels: the adversarial example. \n",
    "### YOUR CODE HERE\n",
    "x, y = X_test[0], Y_test[0]\n",
    "print (\"This is an image of Number\", y)\n",
    "x_adv = clf.attack(x, y)\n",
    "pixels = x_adv.reshape((28,28))\n",
    "### END YOUR CODE\n",
    "\n",
    "plt.imshow(pixels,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) **[5 points]** Try the adversarial attack and test the accuracy of using adversarial examples.\n",
    "\n",
    "You can get a test accuracy of using adversarial examples after running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of adversarial examples is 0.139\n"
     ]
    }
   ],
   "source": [
    "### Output acc: the adversarial accuracy. \n",
    "### YOUR CODE HERE\n",
    "nTest = 1000\n",
    "Y_pred = np.zeros(nTest)\n",
    "for i in range(nTest):\n",
    "    x, y = X_test[i], Y_test[i]\n",
    "    x_adv = clf.attack(x, y)\n",
    "    Y_pred[i] = clf.predict(x_adv)\n",
    "acc = np.sum(Y_pred == Y_test[:nTest])*1.0/nTest\n",
    "### END YOUR CODE\n",
    "print (\"Test accuracy of adversarial examples is\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
